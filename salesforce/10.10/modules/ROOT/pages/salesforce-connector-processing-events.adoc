= Processing Events With Salesforce Connector 10.10
:page-aliases: connectors::salesforce/salesforce-connector-processing-events.adoc

You can use Anypoint Connector for Salesforce (Salesforce Connector) as an inbound connector to stream data from Salesforce into your application. To use the connector this way, use one of these source operations:

* *Subscribe topic listener*
* *Subscribe channel listener*
* *Replay topic listener*
* *Replay channel listener*

[NOTE]
When deploying apps on a distributed environment such as a runtime cluster, the source operation must run on the primary node. If the same source runs on multiple nodes, it causes the consumption of duplicate events.

Each event that travels through your flow contains information about the Salesforce data that changed, including how the data changed and when the change occurred.

Salesforce stores events for 24 hours (or 72 hours for high-volume events). A subscriber to a topic or channel can retrieve events related to that topic or channel during the 24-hour retention window. After the retention window ends, the subscriber can retrieve newer events that have not yet expired.

Salesforce assigns each broadcast event a numeric ID. IDs are incremented, but not necessarily by 1 for each consecutive event. For example, the event following the event with ID 999 can have an ID of 1025. A broadcast event ID is unique for the organization and channel. Salesforce does not reuse the IDs of deleted events.

== Prerequisites

To process events with Salesforce Connector, ensure that you:

* Have access to the Salesforce target resource.
* Have the required Salesforce Streaming API permissions enabled in your organization.
* Create a topic using Salesforce Connector, if it doesn't already exist, before you can receive events for Salesforce changes associated with the topic.

[[objectstoreusage]]
== Object Store Usage in Events

Both Salesforce Connector and Mule runtime engine (Mule) use an object store to persist data for features such as automatic message replay and message redelivery:

* The object store included in Mule for on-premises deployments of Mule apps has no transaction limits.
* The free version of Object Store for CloudHub deployments of Mule apps has a limit of 10 transactions per second.

For more information about object store versions, see https://docs.mulesoft.com/object-store/#object-store-notes[Object Store Notes].

=== Replay Topic and Replay Channel Listener Operations

The *Replay topic* and *Replay channel listener* operations can continue from the last replay ID they received before restarting the application.

When a Mule app starts for the first time, the connector creates an object store that saves data:

* For each message that processes successfully, the connector stores the replay ID associated with the message.
* For each message that fails, the connector stores a number that represents the lowest replay ID for which the processing failed.

These two structures ensure that no message is processed twice and that when the application restarts, it can reprocess the failed messages.

For each message that comes through a topic or streaming channel to which the connector is subscribed, the connector updates the object store information using up to four transactions.

If you have multiple workers deployed in CloudHub, all Mule instances process each message when using the *Replay Topic* operations. To avoid multiple Mule instances processing the same message, you can do one of the following:

* Modify your app to filter out duplicate messages.
* Designate a single worker as a receiver and then use a shared queue to pass the messages to a different worker to process the message.

=== Resume from the Last Replay ID

To enable the *Resume from the Last Replay Id* functionality for the *Replay Topic Listener* and *Replay Channel Listener* sources, the connector must store information about the events that were successfully processed by the flow in which the source is used. The connector uses Object Store to store that information.

The way Object Store stores the necessary data for the *Resume from the Last Replay Id* varies depending on the environment:

* When a Mule app runs locally, the connector creates a persistent store in the file system.
+
If the application stops and restarts, or if a connection issue triggers a reconnection, the data saved in the object store enables the connector to continue processing messages at the point where it previously stopped.
* When a Mule app runs in a cluster with the nodes either on the same machine or on different machines, Mule uses a distributed in-memory object store:
** If the primary node (the one consuming the messages) shuts down, the node that takes over for the primary node does not reprocess the same messages. Instead, the node continues from where the previous node stopped processing the messages.
** If the cluster stops, the data from the object store is lost. When the cluster restarts, the configuration at the source level determines whether the connector reprocesses the messages.

+
To persist data so that the app continues processing events when restarted, create a persistent object store, as described in xref:mule-runtime::creating-and-managing-a-cluster-manually.adoc[Create and Manage a Cluster Manually).
* If you use multiple workers when running the app in CloudHub, all of the workers receive and process the events.

== Multiple Flows That Use the Same Source

Avoid having two or more flows use a source that listens to events on the same channel or topic, because the events will be consumed twice from your user quota. If you have a use case that requires processing the same events in two or more different flows, consider implementing that logic in a single flow instead.

WARNING: Having multiple sources listening to the same events and having the *Resume from the Last Replay Id* option enabled can lead to data corruption and potential loss of events.

== Work with Topic Events

Work with topic events by creating a topic, subscribing to a topic, and replaying topic messages.

[[createtopic]]
=== Create a Topic to Receive Data from Salesforce

When you create a topic, the connector creates a `PushTopic`, which is a special object in Salesforce that binds a name (in this case, the topic's name) and a Salesforce Object Query Language (SOQL) query together. After you create a topic, you can then subscribe to it by its name.

You can use either the *Create* (`create`) or *Publish topic* (`publish-topic`) operation to create a topic. The following example uses the `publish-topic` operation to create a topic:

`<sfdc:publish-topic name="AccountUpdates" query="SELECT Id, Name FROM Account"/>`

Alternatively, you can create a topic in Salesforce by executing code such as this code from an *Enter Apex Code* window, which is accessible through the system logs:

[source,text,linenums]
----
PushTopic pushTopic = new PushTopic();
pushTopic.ApiVersion = 23.0;
pushTopic.Name = 'AllAccounts';
pushTopic.Description = 'All records for the Account object';
pushTopic.Query = 'SELECT Id, Name FROM Account';
insert pushTopic;
System.debug('Created new PushTopic: '+ pushTopic.Id);
----

[[topicsub]]
=== Subscribe to a Topic

To subscribe to a topic, add the *Subscribe topic listener* (`subscribe-topic-listener`) or *Replay topic listener* (`replay-topic-listener`) as a source for your flow. The source acts as an inbound endpoint. Every time the subscription receives an event, the source executes the rest of the flow in your Mule app.

In the following XML example, Mule prints a message to the log at the INFO level when the `AccountUpdates` topic receives an event:

[source,xml,linenums]
----
<flow name="accountUpdatesSubscription">
    <!-- INBOUND ENDPOINT -->
    <sfdc:subscribe-topic-listener topic="AccountUpdates"/>
    <!-- REST OF YOUR FLOW -->
    <logger level="INFO" message="Received an event for Salesforce Object ID #[map-payload:Id]"/>
</flow>
----

You can subscribe to a topic that was not previously published in Salesforce. However, after the topic is published, you won't receive notifications for that topic unless you resubscribe to it.

[[topicrep]]
=== Replay Messages From a Topic

A subscriber can specify which events to receive. By default, a subscriber receives only the events that occur after subscribing. Events outside of the 24-hour retention period (or 72-hour retention period for high-volume events) are discarded.

The *Replay Topic Listener* operation provides these options:

* `ALL`
+
Subscriber receives all events, including past events that are within the 24-hour (or 72-hour) retention period and new events sent after the client subscribes.
* `ONLY_NEW`
+
Subscriber receives new events that are broadcast after the client subscribes.
* `FROM_REPLAY_ID`
+
Subscriber receives all events after the specified event `replayId`.

If you specify either the `ALL` replay option or `ONLY_NEW` replay option, the `replayId` value is ignored.

The *Resume from the Last Replay Id* checkbox enables you to specify an automatic replay of stored events based on the Replay ID of the last event processed by the connector. You can use this functionality when the connector stops listening, such as a during a server shutdown or dropped connection. If the stored Replay ID is outside the 24-hour retention period, the replay option determines what events to replay.

To support the *Resume from Last Replay ID* feature, the connector uses a persistent object store to keep different details regarding the processed messages. This feature is enhanced in Salesforce Connector 10.x to reduce message loss probability and to avoid processing duplicate messages. For more details about how Object Store is used, check the <<objectstoreusage,Object Store Usage>> section.

In the following XML example, the *Replay topic listener* operation acts like an inbound endpoint for the Logger component message:

[source,xml,linenums]
----
<flow name="accountUpdatesReplay">
    <!-- INBOUND ENDPOINT -->
    <sfdc:replay-topic-listener topic="AccountUpdates" replayId="1" replayOption="ALL" autoReplay="true"/>
    <!-- REST OF YOUR FLOW -->
    <logger level="INFO" message="Replayed events: #[payload]"/>
</flow>
----

== Work with Streaming Channel Events

Work with streaming channel events by creating a streaming channel, subscribing to a streaming channel, replaying streaming channel events, and pushing events to a streaming channel.

[[createchannel]]
=== Create a Streaming Channel to Receive Data from Salesforce

To create a streaming channel, you must have the proper Salesforce Streaming API permissions enabled in your organization.

Follow these steps to create a streaming channel:

. Log in to your Salesforce Developer Edition organization.
. Under *All Tabs (+)*, select *Streaming Channels*.
. On the *Streaming Channels* tab, select *New* to create a new streaming channel.
. Enter `/u/notifications/ExampleUserChannel` in the *Streaming Channel Name* field.
. Enter an optional description.

You can also create a streaming channel by using either the connector *Create* operation or the connector *Publish streaming channel* (`publish-streaming-channel`) operation. The following example uses the `publish-streaming-channel` operation:

[source,xml,linenums]
----
<sfdc:publish-streaming-channel
    name="/u/Notifications"
    description="General notifications"/>
----

[[streamsub]]
=== Subscribe to a Streaming Channel

After you create a streaming channel, you can start receiving events by subscribing to the channel. The `subscribe-channel-listener` source acts like an inbound endpoint. In this example, every time a subscription to `/u/TestStreaming` receives an event, it executes the rest of the flow and logs a message at the INFO level:

[source,xml,linenums]
----
<flow name="notificationsChannelSubscription">
  <!-- INBOUND ENDPOINT -->
  <sfdc:subscribe-channel-listener streamingChannel="/u/TestStreaming"/>
  <!-- REST OF YOUR FLOW -->
  <logger level="INFO" message="Received an event: #[payload]"/>
</flow>
----

The *Streaming channel* field of the *Subscribe channel listener* operation does not display change events that are available in the Salesforce environment. However, your connector can subscribe to a streaming channel to obtain this information. For example, to subscribe to the `All Change Events` channel, use `/data/ChangeEvents` as the channel name to which to subscribe.

For more information, see https://developer.salesforce.com/docs/atlas.en-us.change_data_capture.meta/change_data_capture/cdc_subscribe_channels.htm[Subscription Channels] in the Salesforce Change Data Capture Developer Guide.

[[channelrep]]
=== Replay Messages From a Streaming Channel

A streaming channel can replay notifications. The *Replay channel listener* input source acts as an inbound endpoint. You can use it as shown in the following example:

[source,xml,linenums]
----
<flow name="flowStreamingChannelReplay">
    <!-- INBOUND ENDPOINT -->
    <sfdc:replay-channel-listener streamingChannel="/u/Notifications" replayId="1" replayOption="ALL"/>
    <!-- REST OF YOUR FLOW -->
    <logger level="INFO" message="Replayed events: #[payload]"/>
</flow>
----

If you specify either the `ALL` replay option or the `ONLY_NEW` replay option, the `replayId` value is ignored.

The *Resume from the Last Replay Id* checkbox enables you to specify an automatic replay of stored events, based on the Replay ID of the last event processed by the connector. You can use this functionality when the connector stops listening, such as a during a server shutdown or dropped connection. If the stored Replay ID is outside the 24-hour retention period, the replay option determines what events to replay.

To support the *Resume from Last Replay ID* feature, the connector uses a persistent object store to keep different details regarding the processed messages. This feature is enhanced in Salesforce Connector 10.x to reduce message loss probability and to avoid processing duplicate messages. For more details about how Object Store is used, check the <<objectstoreusage,Object Store Usage>> section.

=== Push Events to a Streaming Channel with No Listener

Users can push events to a streaming channel, even if the channel does not have a listener for reading published events. Once a listener is started for the channel, Salesforce Streaming API pushes as many messages it can to the listener, based on the maximum daily limit.

For example, given that the maximum number of delivered event notifications within a 24-hour period for a free Salesfoce organization is 10,000, suppose you publish 15,000 events to that channel. When Salesforce Connector subscribes to that channel, the Streaming API attempts to push 10,000 events, thus consuming the daily quota. The API will then attempt to push the remaining 5,000 events the next day before pushing any new events.

In this scenario, the connector streams the events one-by-one into the Mule app. If the app takes too long to process a message, the Salesforce Streaming API might instruct the connector to reconnect. If this happens, the Streaming API drops all of the unprocessed messages.

You can avoid this situation by implementing a reliability pattern, as described in xref:mule-runtime::reliability-patterns.adoc[Reliability Patterns].

[[customevents]]
== Work with Custom Events

Work with custom events by obtaining custom event notifications and pushing custom events to a streaming channel.

=== Obtain Custom Event Notifications

Salesforce Connector enables you to obtain custom event notifications, which apply to general events that are not tied to Salesforce data changes.

To obtain custom event notifications:

. Use the *Publish streaming channel* operation to create a streaming channel.
+
`StreamingChannel` is a special Salesforce object that represents a channel used to notify listeners of generic Streaming API events.
+
You can also create a streaming channel through Salesforce or https://workbench.developerforce.com/about.php[Workbench].
+
. Use the *Subscribe channel listener* operation to subscribe to the channel.
+
Salesforce Connector converts the custom events in your streaming channel to Mule events.

For more information about working with streaming channels, see <<createchannel,Create a Streaming Channel to Receive Data from Salesforce>> and <<eventshandling,Handling Events with Salesforce Connector>>.

[[pushevents]]
=== Push Custom Events to a Streaming Channel

Salesforce enables you to push custom events to a specific streaming channel through the REST API. To do this, use https://workbench.developerforce.com/about.php[Workbench] or this connector.

The following example uses the connector's `push-generic-event` operation to push custom events to the channel with the ID `0M6j0000000KyjBCAS`:

[source,xml,linenums]
----
<flow name="flowPushGenericEvent">
    <!-- INBOUND ENDPOINT -->
    <sfdc:push-generic-event channelId="0M6j0000000KyjBCAS">
      <sfdc:events>
            <sfdc:event payload="Notification message text"/>
        </sfdc:events>
  </sfdc:push-generic-event>
    <logger level="INFO" message="Replayed events: #[payload]"/>
</flow>
----

You can retrieve the channel ID from the response map of the `publish-streaming-channel` operation. Alternatively, you can retrieve the channel ID from the Salesforce page:

. Log in to your Salesforce Developer Edition organization.
. Under *All Tabs (+)*, select *Streaming Channels*.

If the channel ID field is not visible on the channel list, follow these steps:

. Click *Create New View*.
. Type a name for the view in the *Name* input field.
. In the *Available Fields* list, select *Streaming Channel ID* and click *Add*.
+
You should see the channel ID for each streaming channel in the list.
+
. Add any other fields.
. Click *Save*.

The JSON received as a response from the push event operation looks something like this:

[source,json,linenums]
----
[
  {
  "userOnlineStatus": {
  },
  "fanoutCount": 0
  }
]
----

== See Also

* xref:connectors::introduction/introduction-to-anypoint-connectors.adoc[Introduction to Anypoint Connectors]
* xref:salesforce-connector-config-topics.adoc[Additional Configuration]
* xref:salesforce-connector-examples.adoc[Examples]
* https://help.mulesoft.com[MuleSoft Help Center]
