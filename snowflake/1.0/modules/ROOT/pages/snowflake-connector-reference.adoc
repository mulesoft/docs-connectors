= Snowflake Connector 1.0 Reference

== Snowflake Configuration

=== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
|Name | String | The name for this configuration. Connectors reference the configuration with this name. | | x
| Connection a| <<snowflake-config_snowflake-connection, Snowflake Connection>>
 | The connection types to provide to this configuration. | | x
| Expiration Policy a| <<ExpirationPolicy>> |  Configures the minimum amount of time that a dynamic configuration instance can remain idle before Mule considers it eligible for expiration. |  |
|===

[[snowflake-config_snowflake-connection]]
== Snowflake Connection


=== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Pooling Profile a| <<SnowflakeDbPoolingProfile>> |  Provides a way to configure database connection pooling. |  |
| Account Name a| String |  Account name that was provided when registering for the Snowflake account.  |  | x
| Warehouse a| String |  Name of the Snowflake warehouse to use. |  | x
| Database a| String |  Snowflake database to connect to. |  | x
| Schema a| String |  Snowflake database schema to use. |  | x
| User a| String |  Snowflake database username used to initialize the session. |  |
| Password a| String | Snowflake database password used to authenticate the user. |  |
| Role a| String | Role assigned to the user. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment fails if the test doesn't pass after exhausting the associated reconnection strategy. |  |
|===

== Supported Operations

* <<bulkDelete>>
* <<bulkInsert>>
* <<bulkUpdate>>
* <<copyIntoLocation>>
* <<copyIntoTable>>
* <<copyIntoTableWithTransformation>>
* <<createPipe>>
* <<createStage>>
* <<createTask>>
* <<delete>>
* <<executeDdl>>
* <<executeScript>>
* <<insert>>
* <<insertMultiTable>>
* <<merge>>
* <<select>>
* <<storedProcedure>>
* <<update>>

== Operations

[[bulkDelete]]
=== Bulk Delete
`<snowflake:bulk-delete>`

Enables execution of a single delete statement at various times using different parameter bindings. Using a single database statement has performance advantages compared to executing a single operation at various times.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Input Parameters a| Array of Object |  A list of maps in which every list item represents a row to delete. The map contains the parameter names as keys and the value the parameter is bound to. |  #[payload] |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by this message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> | Optionally specifies the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that isn't present in the input values. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Number
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[bulkInsert]]
=== Bulk Insert
`<snowflake:bulk-insert>`

Enables execution of a single insert statement at various times using different parameter bindings. Using a single database statement has performance advantages compared to executing a single update operation at various times.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Input Parameters a| Array of Object | A list of maps in which every list item represents a row to delete. The map contains the parameter names as keys and the value the parameter is bound to. |  #[payload] |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> |  Allows you to optionally specify the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that isn't present in the input values. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Number
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[bulkUpdate]]
=== Bulk Update
`<snowflake:bulk-update>`

Enables execution of a single update statement at various times using different parameter bindings. Using a single database statement has performance advantages compared to executing a single update operation at various times.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Input Parameters a| Array of Object | A list of maps in which every list item represents a row to delete. The map contains the parameter names as keys and the value the parameter is bound to. |  #[payload] |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can take regarding transactions. |  JOIN_IF_POSSIBLE |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value (10) is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> | Enables you to optionally specify the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that isn't present in the input values. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Number
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[copyIntoLocation]]
=== Copy Into Location
`<snowflake:copy-into-location>`

Unloads data from a table (or query) into one or more files.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Location a| One of:

* <<SnowflakeLocation>>
* <<ExternalLocation>> |  Specifies the internal or external location where the files containing the data to load are staged. |  | x
| Table Query Source a| One of:

* <<table>>
* <<query>> |  Specifies the table or query used as the source of the data to unload. |  | x
| File Format a| One of:

* <<DefinitionByNameForCopyIntoLocation>>
* <<DefinitionByTypeForCopyIntoLocation>> |  Specifies the format of the data files to load. |  |
| Include Header a| Boolean |  Specifies whether to include the table column headings in the output files. |  false |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Overwrite a| Boolean |  Boolean that specifies whether the COPY command overwrites existing files with matching names in the location where the files are stored. |  false |
| Single a| Boolean |  Boolean that specifies whether to generate a single file or multiple files. If `false`, a filename prefix must be included in the path. |  false |
| Max File Size a| Number |  Number (> 0) that specifies the upper size limit (in bytes) of each file to generate in parallel per thread. |  16000000 |
| Include Query Id a| Boolean |  Boolean that specifies whether to uniquely identify unloaded files by including a universally unique identifier (UUID) in the filenames of unloaded data files. |  false |
| Detailed Output a| Boolean |  Specifies whether to load data into columns in the target table that match corresponding columns represented in the data. |  false |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  Retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Object
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[copyIntoTable]]
=== Copy Into Table
`<snowflake:copy-into-table>`


Loads data from staged files to an existing table. The files must already be staged in one of the following locations:

- Named internal stage (or table/user stage). Files can be staged using the PUT command.
- Named external stage that references an external location (Amazon S3, Google Cloud Storage, or Microsoft Azure).
- External location (Amazon S3, Google Cloud Storage, or Microsoft Azure).


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Destination Table Name a| String |  Specifies the name of the table into which data is loaded. |  | x
| Location a| One of:

* <<SnowflakeLocation>>
* <<ExternalLocation>> |  Specifies the internal or external location where the files containing the data to be loaded are staged. |  | x
| Files a| Array of String |  Specifies a list of one or more files to load from a staged internal or external location. |  |
| Pattern a| String |  Specifies the file names or paths to match based on a regex pattern. |  |
| File Format a| One of:

* <<DefinitionByNameForCopyIntoTable>>
* <<DefinitionByTypeForCopyIntoTable>> |  Specifies the format of the data files to load. |  |
| Validation Mode a| One of:

* <<ValidationModeReturnErrors>>
* <<ValidationModeReturnMaxRows>> |  Specifies that the load operation should only validate data and return the results based on validation options rather than loading data into the specified table. |  |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| On Error a| String |  Action to perform when an error is seen while loading data from a file. |  |
| Size Limit a| Number | Maximum size in bytes of data to load with a given copy statement. |  |
| Purge a| Boolean |  Specifies whether to remove the data files from the stage automatically after the data is loaded successfully. |  false |
| Return Failed Only a| Boolean |  Specifies whether to return only files that have failed to load in the statement result. |  false |
| Match By Column Name a| Enumeration, one of:

** CASE_SENSITIVE
** CASE_INSENSITIVE
** NONE |  Specifies whether to load data into columns in the target table that match corresponding columns represented in the data. |  NONE |
| Enforce Length a| Boolean |  Specifies whether to truncate text strings that exceed the target column length. |  true |
| Truncate Columns a| Boolean |  Specifies whether to truncate text strings that exceed the target column length. |  false |
| Force a| Boolean |  If `true`, loads all files, regardless of whether they've been loaded previously and have not changed since they were loaded. |  false |
| Load Uncertain Files a| Boolean | Specifies to load files for which the load status is unknown. |  false |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Object
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[copyIntoTableWithTransformation]]
=== Copy Into Table With Transformation
`<snowflake:copy-into-table-with-transformation>`


Loads data from staged files to an existing table. The files must already be staged in one of the following locations:

- Named internal stage (or table/user stage). Files can be staged using the PUT command.
- Named external stage that references an external location (Amazon S3, Google Cloud Storage, or Microsoft Azure).
- External location (Amazon S3, Google Cloud Storage, or Microsoft Azure).


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Destination Table Name a| String |  Specifies the name of the table into which data is loaded. |  | x
| Column Names a| Array of String |  Specifies an explicit list of table columns (separated by commas) into which you want to insert data. |  |
| Transformation Select SQL a| String |  Specifies an explicit set of fields or columns (separated by commas) to load from the staged data files. |  | x
| Stage Name a| String |  Specifies the internal or external location where the files containing the data to be loaded are staged. |  | x
| Stage Alias a| String a|  Specifies an optional alias for the FROM value (for example `d` in `COPY INTO t1 (c1) FROM (SELECT d.$1 FROM @mystage/file1.csv.gz d));`). |  |
| Files a| Array of String |  Specifies a list of one or more files to load from a staged internal or external location. |  |
| Pattern a| String |  Specifies the file names or paths to match based on a regular expression pattern. |  |
| File Format a| One of:

* <<DefinitionByNameForCopyIntoTable>>
* <<DefinitionByTypeForCopyIntoTable>> | Specifies the format of the data files to load. |  |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| On Error a| String | Action to perform when an error is seen while loading data from a file. |  |
| Size Limit a| Number | Maximum size in bytes of data to be loaded with a given copy statement. |  |
| Purge a| Boolean |  Specifies whether to remove the data files from the stage automatically after the data is loaded successfully. |  false |
| Return Failed Only a| Boolean |  Specifies whether to return only files that have failed to load in the statement result. |  false |
| Match By Column Name a| Enumeration, one of:

** CASE_SENSITIVE
** CASE_INSENSITIVE
** NONE |  Specifies whether to load data into columns in the target table that match corresponding columns represented in the data. |  NONE |
| Enforce Length a| Boolean |  Specifies whether to truncate text strings that exceed the target column length. |  true |
| Truncate Columns a| Boolean |  Specifies whether to truncate text strings that exceed the target column length. |  false |
| Force a| Boolean | If true, loads all files, regardless of whether they've been loaded previously and have not changed since they were loaded. |  false |
| Load Uncertain Files a| Boolean | Specifies to load files for which the load status is unknown. |  false |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Object
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[createPipe]]
=== Create Pipe
`<snowflake:create-pipe>`

Creates a new pipe in the system for defining the COPY INTO <table> statement used by Snowpipe to load data from an ingestion queue into tables.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Pipe Name a| String |  Specifies the identifier for the pipe; must be unique for the schema in which the pipe is created. |  | x
| Copy Statement a| String |  Specifies the statement used to load data from queued files into a Snowflake table. This statement serves as the text/definition for the pipe and is displayed in the SHOW PIPES output. |  | x
| Replace Existing Pipe a| Boolean |  Specifies if an already existing pipe should be overwritten by the one being created. |  false |
| If Not Exists a| Boolean |  Specifies if the pipe should be created if there isn't already an existing pipe with the same name. |  false |
| Auto Ingest a| One of:

* <<true>>
* <<false>> |  Specifies whether data should be automatically loaded from the specified external stage and optional path when event notifications are received from a configured message service. |  |
| Comment a| String |  Specifies a comment for the pipe. |  |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Boolean
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[createStage]]
=== Create Stage
`<snowflake:create-stage>`

Creates a new named stage to use for loading data from files into Snowflake tables and unloading data from tables into files.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Stage Location a| One of:

* <<InternalStageLocation>>
* <<ExternalStageLocation>> |  Snowflake internal or external location to create the stage. |  | x
| If Not Exists a| Boolean |  Specifies if the stage should not be created if there is already an existing stage with the same name. |  false |
| Replace Already Existing Stage a| Boolean |  Specifies if an already existing stage should be overwritten by the one being created. |  false |
| Is Temporary a| Boolean |  Specifies whether or not the stage being created is temporary. |  false |
| File Format a| One of:

* <<FileFormatDefinitionByName>>
* <<FileFormatDefinitionByTypeOptions>> |  Specifies the type of files for the stage. |  |
| Comment a| String |  Specifies a comment for the stage. |  |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| On Error a| String |  Action to perform when an error is seen while loading data from a file. |  |
| Size Limit a| Number |  Maximum size in bytes of data to load with a given copy statement. |  |
| Purge a| Boolean |  Specifies whether to remove the data files from the stage automatically after the data is loaded successfully. |  false |
| Return Failed Only a| Boolean |  Specifies whether to return only files that have failed to load in the statement result. |  false |
| Match By Column Name a| Enumeration, one of:

** CASE_SENSITIVE
** CASE_INSENSITIVE
** NONE |  Specifies whether to load data into columns in the target table that match corresponding columns represented in the data. |  NONE |
| Enforce Length a| Boolean |  Specifies whether to truncate text strings that exceed the target column length. |  true |
| Truncate Columns a| Boolean |  Specifies whether to truncate text strings that exceed the target column length. |  false |
| Force Load a| Boolean | If `true`, loads all files, regardless of whether they've been loaded previously and have not changed since they were loaded. |  false |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Boolean
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[createTask]]
=== Create Task
`<snowflake:create-task>`

Creates a new named external stage to use for:

* Loading data from files into Snowflake tables
* Unloading data from tables into files

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Task Name a| String |  Specifies the name of the task; must be unique for the schema in which the task is created. |  | x
| Warehouse Name a| String |  Specifies the name of the warehouse. |  | x
| Sql a| String |  Specifies the query to run. |  | x
| Replace Existing Task a| Boolean |  Specifies if an existing task should be overwritten by the one being created. |  false |
| If Not Exists a| Boolean |  Specifies if the task should be created if there isn't already an existing task with the same name. |  false |
| Session Parameters a| Object |  Specifies the session parameters to set for the session when the task runs. |  |
| Run Timeout a| Number |  Specifies a time limit in milliseconds on a single task run before it times out. |  |
| Copy Grants a| Boolean |  Specifies whether access permissions from the original task should be retained when cloning or replacing an existing task. |  false |
| Comment a| String |  Specifies a comment for the task. |  |
| After Task a| String |  Specifies the name of a predecessor task which would trigger the created task whenever the predecessor task is run. |  |
| When a| String |  SQL expression to determine whether a task should run. |  |
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Schedule Option Cron Expression a| <<ScheduleOptionCronExpression>> |  Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax. |  |
| Schedule Option Time Interval a| <<ScheduleOptionTimeInterval>> |  Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Boolean
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[delete]]
=== Delete
`<snowflake:delete>`

Removes data from a table using an optional WHERE clause and/or additional tables.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> | Optionally specify the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that isn't present in the input values. |  |
| Input Parameters a| Object | Map in which keys are the name of an input parameter to set on the JDBC prepared statement. Reference each parameter in the SQL text using a colon as the prefix, for example where `ID = :myParamName`.  The map's values will contain the actual assignation for each parameter. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Number
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[executeDdl]]
=== Execute Ddl
`<snowflake:execute-ddl>`


Data Definition Language (DDL) commands are used to create, manipulate, and modify objects in Snowflake, such as users, virtual warehouses, databases, schemas, tables, views, columns, functions, and stored procedures.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| SQL String a| String |  SQL DDL statement to execute. |  | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Number
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[executeScript]]
=== Execute Script
`<snowflake:execute-script>`

Executes a SQL script in one single database statement. The script is executed as provided by the user, without any parameter binding.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| SQL Query Text a| String |  |  |
| Script Path a| String |  |  |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Number
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY


[[insert]]
=== Insert
`<snowflake:insert>`

Updates a table by inserting one or more rows into the table. The values inserted into each column in the table can be explicitly specified or they can be the results of a query.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> |  Optionally specify the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that isn't present in the input values. |  |
| Input Parameters a| Object |   Map in which keys are the name of an input parameter to set on the JDBC prepared statement. Reference each parameter in the SQL text using a colon as the prefix, for example where `ID = :myParamName`.  The map's values will contain the actual assignation for each parameter. |  |
| Auto Generate Keys a| Boolean |  Indicates when to make auto-generated keys available for retrieval. |  false |
| Auto Generated Keys Column Indexes a| Array of Number |  List of column indexes that indicates which auto-generated keys to make available for retrieval. |  |
| Auto Generated Keys Column Names a| Array of String |  List of column names that indicates which auto-generated keys to make available for retrieval. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |<<StatementResult>>
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY


[[insertMultiTable]]
=== Insert Multi Table
`<snowflake:insert-multi-table>`

Updates multiple tables by inserting one or more rows with column values (from a query) into the tables. Supports both unconditional and conditional inserts.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Insert Into Multi Table Parameters a| One of:

* <<Conditional>>
* <<Unconditional>> |  |  | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Boolean
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY


[[merge]]
=== Merge
`<snowflake:merge>`

Inserts, updates, and deletes values in a table based on values in a second table or a subquery.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Target Table a| String |  Specifies the table to merge. |  | x
| Source a| String | Specifies the table or subquery to join with the target table. |  | x
| Join Expr a| String |Specifies the expression on which to join the target table and source.  |  | x
| Match Clauses a| Array of One of:

* <<NotMatchedInsertClause>>
* <<MatchedUpdateClause>>
* <<MatchedDeleteClause>> |  Specifies a list of clauses and actions to perform when a match occurs or does not occur. |  | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Boolean
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[select]]
=== Select
`<snowflake:select>`

SELECT can be used in both a statement and a clause within a SELECT statement. As a statement, the SELECT statement is the most commonly executed SQL statement; it queries the database and retrieves a set of rows. As a clause, SELECT defines the set of columns returned by a query.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Streaming Strategy a| * <<repeatable-in-memory-iterable>>
* <<repeatable-file-store-iterable>>
* non-repeatable-iterable |  Configures how Mule processes streams. The default is to use repeatable streams. |  |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> | Optionally specify the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that isn't present in the input values. |  |
| Input Parameters a| Object | Map in which keys are the name of an input parameter to set on the JDBC prepared statement. Reference each parameter in the SQL text using a colon as the prefix, for example where `ID = :myParamName`.  The map's values will contain the actual assignation for each parameter. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of Object
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[storedProcedure]]
=== Stored Procedure
`<snowflake:stored-procedure>`


Invokes a stored procedure on the database.  When the stored procedure returns one or more result set instances, streaming is automatically applied to avoid preemptive consumption of such results, which can lead to performance and memory issues.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* non-repeatable-stream |  Configures how Mule processes streams. The default is to use repeatable streams. |  |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a result set. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> | Optionally specify the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that isn't present in the input values. |  |
| Input Parameters a| Object | Map in which keys are the name of an input parameter to set on the JDBC prepared statement. Reference each parameter in the SQL text using a colon as the prefix, for example where `ID = :myParamName`.  The map's values will contain the actual assignation for each parameter. |  |
| Auto Generate Keys a| Boolean |  Indicates when to make auto-generated keys available for retrieval. |  false |
| Auto Generated Keys Column Indexes a| Array of Number |  List of column indexes that indicates which auto-generated keys to make available for retrieval. |  |
| Auto Generated Keys Column Names a| Array of String |  List of column names that indicates which auto-generated keys should be made available for retrieval. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Object
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE


[[update]]
=== Update
`<snowflake:update>`

Updates specified rows in the target table with new values.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | Name of the configuration to use. | | x
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  Type of joining action that operations can perform for transactions. |  JOIN_IF_POSSIBLE |
| Query Timeout a| Number |  Indicates the minimum amount of time before the JDBC driver attempts to cancel a running statement. No timeout is used by default. |  0 |
| Query Timeout Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  Time unit for the *Query Timeout* field. |  SECONDS |
| Fetch Size a| Number |  Indicates how many rows to fetch from the database when rows are read from a resultSet. This property is required when streaming is true, in which case a default value of 10 is used. |  |
| Max Rows a| Number |  Sets the limit for the maximum number of rows that any Result set object generated by the message processor can contain for the given number. If the limit is exceeded, the excess rows are silently dropped. |  |
| SQL String a| String |  Text of the SQL query to execute. |  | x
| Parameter Types a| Array of <<ParameterType>> | Optionally specify the type of one or more of the parameters in the query. If provided, you're not required to reference all of the parameters, but you can't reference a parameter that's not present in the input values. |  |
| Input Parameters a| Object | Map in which keys are the name of an input parameter to set on the JDBC prepared statement. Reference each parameter in the SQL text using a colon as the prefix, for example where `ID = :myParamName`.  The map's values will contain the actual assignation for each parameter. |  |
| Auto Generate Keys a| Boolean |  Indicates when to make auto-generated keys available for retrieval. |  false |
| Auto Generated Keys Column Indexes a| Array of Number |  List of column indexes that indicates which auto-generated keys to make available for retrieval. |  |
| Auto Generated Keys Column Names a| Array of String |  List of column names that indicates which auto-generated keys to make available for retrieval. |  |
| Target Variable a| String |  Name of the variable that stores the operation's output. |  |
| Target Value a| String |  Expression that evaluates the operation’s output. The outcome of the expression is stored in the *Target Variable* field. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |<<StatementResult>>
|===

=== For Configurations
* <<snowflake-config>>

==== Throws
* SNOWFLAKE:RETRY_EXHAUSTED
* SNOWFLAKE:CONNECTIVITY
* SNOWFLAKE:NOT_FOUND
* SNOWFLAKE:QUERY_EXECUTION
* SNOWFLAKE:INVALID_CREDENTIALS
* SNOWFLAKE:INVALID_INPUT
* SNOWFLAKE:CANNOT_LOAD_DRIVER
* SNOWFLAKE:UNKNOWN_SNOWFLAKE_ERROR
* SNOWFLAKE:DATABASE



== Types

[[SnowflakeDbPoolingProfile]]
=== Snowflake Db Pooling Profile

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Max Pool Size a| Number | Maximum number of connections a pool maintains at any given time | 5 |
| Min Pool Size a| Number | Minimum number of connections a pool maintains at any given time | 0 |
| Acquire Increment a| Number | Determines how many connections at a time to try to acquire when the pool is exhausted | 1 |
| Prepared Statement Cache Size a| Number | Determines how many statements are cached per pooled connection. Setting this to zero will disable statement caching | 5 |
| Max Wait a| Number | The amount of time a client trying to obtain a connection waits for it to be acquired when the pool is
 exhausted. Zero (default) means wait indefinitely | 0 |
| Max Wait Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS | A #maxWait. | SECONDS |
| Max Idle Time a| Number | Determines how many seconds a Connection can remain pooled but unused before being discarded.
 Zero means idle connections never expire. | 0 |
| Additional Properties a| Object |  |  |
|===

[[Reconnection]]
=== Reconnection

Reconnection strategy to use.

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Fails Deployment a| Boolean | When the application is deployed, a connectivity test is performed on all connectors. If set to `true`, deployment fails if the test doesn't pass after exhausting the associated reconnection strategy. |  |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> | The reconnection strategy to use. |  |
|===

[[reconnect]]
=== Reconnect

Configures a standard reconnection strategy, which specifies how often to reconnect and how many reconnection attempts the connector source or operation can make.

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often in milliseconds to reconnect |  |
| Count a| Number | How many reconnection attempts to make. |  |
|===

[[reconnect-forever]]
=== Reconnect Forever

Configures a forever reconnection strategy by which the connector operation source or operation attempts to reconnect at a specified frequency for as long as the Mule app runs.

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often in milliseconds to reconnect. |  |
|===

[[ExpirationPolicy]]
=== Expiration Policy

Configures the minimum amount of time that a dynamic configuration instance can remain idle before Mule considers it eligible for expiration.

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Max Idle Time a| Number | A scalar time value for the maximum amount of time a dynamic configuration instance should be allowed to be idle before it's considered eligible for expiration |  |
| Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS | A time unit that qualifies the maxIdleTime attribute |  |
|===

[[ParameterType]]
=== Parameter Type

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Key a| String | The name of the input parameter. |  | x
| Type Classifier a| <<TypeClassifier>> |  |  | x
|===

[[TypeClassifier]]
=== Type Classifier

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Type a| Enumeration, one of:

** BIT
** TINYINT
** SMALLINT
** INTEGER
** BIGINT
** FLOAT
** REAL
** DOUBLE
** NUMERIC
** DECIMAL
** CHAR
** VARCHAR
** LONGVARCHAR
** DATE
** TIME
** TIMESTAMP
** BINARY
** VARBINARY
** LONGVARBINARY
** NULL
** OTHER
** JAVA_OBJECT
** DISTINCT
** STRUCT
** ARRAY
** BLOB
** CLOB
** REF
** DATALINK
** BOOLEAN
** ROWID
** NCHAR
** NVARCHAR
** LONGNVARCHAR
** NCLOB
** SQLXML
** UNKNOWN |  |  |
| Custom Type a| String |  |  |
|===

[[ScheduleOptionCronExpression]]
=== Schedule Option Cron Expression

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Cron Expression a| String | Specifies a cron expression that identifies when to repeat runs of the task. |  | x
| Time Zone a| String | Specifies the time zone to use for the cron expression. |  | x
|===

[[ScheduleOptionTimeInterval]]
=== Schedule Option Time Interval

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Time Interval In Minutes a| Number | Specifies a time interval in minutes to wait between periodic runs of the task.
 Also supports num M syntax. |  | x
|===

[[StatementResult]]
=== Statement Result

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Affected Rows a| Number |  |  |
| Generated Keys a| Object |  |  |
|===

[[repeatable-in-memory-iterable]]
=== Repeatable In Memory Iterable

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Initial Buffer Size a| Number | The number of instances to initially keep in memory to consume the stream and provide random access to it. If the stream contains more data than can fit into this buffer, then the buffer expands according to the bufferSizeIncrement attribute, with an upper limit of maxInMemorySize. Default value is 100 instances. |  |
| Buffer Size Increment a| Number | This is by how much the buffer size expands if it exceeds its initial size. Setting a value of zero or lower means that the buffer should not expand, meaning that a STREAM_MAXIMUM_SIZE_EXCEEDED error is raised when the buffer gets full. Default value is 100 instances. |  |
| Max Buffer Size a| Number | The maximum amount of memory to use. If more than that is used then a STREAM_MAXIMUM_SIZE_EXCEEDED error is raised. A value lower than or equal to zero means no limit. |  |
|===

[[repeatable-file-store-iterable]]
=== Repeatable File Store Iterable

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| In Memory Objects a| Number | The maximum amount of instances to keep in memory. If more than that is required, content on the disk is buffered. |  |
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which maxInMemorySize is expressed |  |
|===

[[repeatable-in-memory-stream]]
=== Repeatable In Memory Stream

When streaming in this mode, Mule does not use the disk to buffer the contents. If you exceed the buffer size, the message fails.

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Initial Buffer Size a| Number | The amount of memory to allocate to consume the stream and provide random access to it. If the stream contains more data than can fit into this buffer, the buffer expands according to the bufferSizeIncrement attribute, with an upper limit of maxInMemorySize. |  |
| Buffer Size Increment a| Number | This is by how much the buffer size expands if it exceeds its initial size. Setting a value of zero or lower means that the buffer should not expand, meaning that a STREAM_MAXIMUM_SIZE_EXCEEDED error is raised when the buffer gets full. |  |
| Max Buffer Size a| Number | Maximum amount of memory to use. If more than what is specified is used then a STREAM_MAXIMUM_SIZE_EXCEEDED error is raised. A value lower than or equal to zero means no limit. |  |
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which all these attributes are expressed |  |
|===

[[repeatable-file-store-stream]]
=== Repeatable File Store Stream

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| In Memory Size a| Number | Defines the maximum memory that the stream should use to keep data in memory. If more than that is consumed content on the disk is buffered. |  |
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which maxInMemorySize is expressed |  |
|===

[[Avro]]
=== Avro

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first value to convert to from SQL NULL. |  |
|===

[[FileFormatOptionsCsv]]
=== File Format Options CSV

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Record Delimiter a| String | One or more single-byte or multibyte characters that separate records in an input file or unloaded file. |  | x
| Field Delimiter a| String | One or more single-byte or multibyte characters that separate records in an input file or unloaded file. | , |
| File Extension a| String |  |  |
| Skip Header Count a| Number |  | 0 |
| Skip Blank Lines a| Boolean | Specifies whether to skip any blank lines encountered in data, instead of resulting in an end-of-record error. | false |
| Date Format a| String |  | Auto |
| Time Format a| String |  | Auto |
| Timestamp Format a| String |  | Auto |
| Binary Format a| Enumeration, one of:

** HEX
** BASE64
** UTF8 |  | HEX |
| Escape Character a| String |  |  |
| Escape Unenclosed Field Character a| String | Specifies a single character used as the escape character for unenclosed field values only. |  |
| Trim Space a| Boolean |  | false |
| Field Optionally Enclosed By a| String |  |  |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first one to convert to from SQL NULL. |  | x
| Error On Column Count Mismatch a| Boolean | Specifies whether to generate a parsing error if the number of delimited columns (i.e. fields) in an input file does not match the number of columns in the corresponding table. | true |
| Replace Invalid Characters a| Boolean | Specifies whether to replace invalid UTF-8 characters with a default Unicode character instead of resulting in an error. | false |
| Validate UTF8 a| Boolean |  | true |
| Empty Field As Null a| Boolean | When set to `false`, allows empty strings to be loaded in tables without enclosing the field values in quotes. | true |
| Skip Byte Order Mark a| Boolean | Specifies whether to skip any byte order mark information from input files so that they wouldn't cause errors or be merged into the first table column. | true |
| Encoding a| Enumeration, one of:

** BIG5
** EUCJP
** EUCKR
** GB18030
** IBM420
** IBM424
** ISO2022CN
** ISO2022JP
** ISO2022KR
** ISO88591
** ISO88592
** ISO88595
** ISO88596
** ISO88597
** ISO88598
** ISO88599
** KOI8R
** SHIFTJIS
** UTF8
** UTF16
** UTF16BE
** UTF16LE
** UTF32
** UTF32BE
** UTF32LE
** WINDOWS1250
** WINDOWS1251
** WINDOWS1252
** WINDOWS1253
** WINDOWS1254
** WINDOWS1255
** WINDOWS1256 |  | UTF8 |
|===

[[FileFormatOptionsJson]]
=== File Format Options JSON

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Date Format a| String |  | Auto |
| Time Format a| String |  | Auto |
| Timestamp Format a| String |  | Auto |
| Binary Format a| Enumeration, one of:

** HEX
** BASE64
** UTF8 |  | HEX |
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first value to convert to from SQL NULL. |  |
| File Extension a| String |  |  |
| Enable Octal a| Boolean |  | false |
| Allow Duplicate a| Boolean |  | false |
| Strip Outer Array a| Boolean |  | false |
| Strip Null Values a| Boolean | Specifies that the JSON parser should remove object fields or array elements containing null values. | false |
| Replace Invalid Characters a| Boolean | Specifies whether to replace invalid UTF-8 characters with a default Unicode character instead of resulting in an error. | false |
| Ignore UTF8 Errors a| Boolean | Specifies whether to suppress UTF-8 encoding errors and silently replace with a default Unicode character. | false |
| Skip Byte Order Mark a| Boolean | Specifies whether to skip any byte order mark information from input files so that they won't cause errors or be merged into the first table column. | true |
|===

[[ORC]]
=== ORC

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first value to convert to from SQL NULL. |  |
|===

[[Parquet]]
=== Parquet

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** LZO
** SNAPPY
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Binary As Text a| Boolean | Specifies whether to interpret columns with no defined logical data type as UTF-8 text when set to true, or binary data when set to false. | true |
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first value to convert to from SQL NULL. |  |
|===

[[XML]]
=== XML

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Ignore UTF8 Errors a| Boolean | Specifies whether to suppress UTF-8 encoding errors and silently replace with a default Unicode character. | false |
| Preserve Space a| Boolean | Specifies whether the XML parser preserves leading and trailing spaces in element content. | false |
| Strip Outer Element a| Boolean | Specifies whether the XML parser strips out the outer XML element, exposing second-level elements as separate documents. | false |
| Disable Snowflake Data a| Boolean | Specifies whether the XML parser disables recognition of Snowflake semi-structured data tags. | false |
| Disable Auto Convert a| Boolean | Specifies whether the XML parser disables automatic conversion of numeric and Boolean values from text to native representation. | false |
| Skip Byte Order Mark a| Boolean | Specifies whether to skip any byte order mark information from input files so that they won't cause errors or be merged into the first table column. | true |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first value to convert to from SQL NULL. |  |
|===

[[FileFormatDefinitionByName]]
=== File Format Definition By Name

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| File Format Name a| String | Specifies an existing named file format to use for loading and unloading data into or from the table.
 The named file format determines the format type (CSV, JSON, PARQUET), as well as any other format options, for the data files. |  | x
|===

[[FileFormatDefinitionByTypeOptions]]
=== File Format Definition By Type Options

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Format Type Options a| One of:

* <<Avro>>
* <<FileFormatOptionsCsv>>
* <<FileFormatOptionsJson>>
* <<ORC>>
* <<Parquet>>
* <<XML>> | Specifies the type of files loaded and unloaded into or from the table.
 If a format type is specified, additional format-specific options can be specified. |  | x
|===

[[true]]
=== True

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Sns Topic a| String | Required only when configuring AUTO_INGEST for Amazon S3 stages using Amazon Simple Notification Service (SNS).
 Specifies the Amazon Resource Name (ARN) for the SNS topic for your S3 bucket.
 The CREATE PIPE statement subscribes the Amazon Simple Queue Service (SQS) queue to the specified SNS topic.
 The pipe copies files to the ingest queue triggered by event notifications via the SNS topic. |  |
| Integration a| String | Required only when configuring AUTO_INGEST for Google Cloud Storage or Microsoft Azure stages.
 Specifies the existing notification integration used to access the storage queue. |  |
|===

[[ValidationModeReturnErrors]]
=== Validation Mode Return Errors

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Validation Error Type a| Enumeration, one of:

** RETURN_ERRORS
** RETURN_ALL_ERRORS |  |  | x
|===

[[ValidationModeReturnMaxRows]]
=== Validation Mode Return Max Rows

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Max Rows a| Number |  |  | x
|===

[[SnowflakeLocation]]
=== Snowflake Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Stage Name a| String a| Files are unloaded to the specified Snowflake location (internal/external stage, table, path):

   - [namespace.]int_stage_name[/path] = Files are unloaded to the specified named internal stage.
   - [namespace.]ext_stage_name[/path] = Files are unloaded to the specified named external stage.
   - [namespace.]%table_name[/path] = Files are unloaded to the stage for the specified table.
   - ~[/path] = Files are unloaded to the stage for the current user. |  | x
|===

[[ExternalLocation]]
=== External Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| External Location Provider a| One of:

* <<MicrosoftAzure>>
* <<GoogleCloudStorage>>
* <<AmazonS3>> | External system to integrate with Snowflake |  | x
|===

[[InternalStageLocation]]
=== Internal Stage Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Stage Name a| String | Internal stage name. |  | x
|===

[[ExternalStageLocation]]
=== External Stage Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Stage Name a| String | External stage name. |  | x
| External Location Provider a| One of:

* <<MicrosoftAzure>>
* <<GoogleCloudStorage>>
* <<AmazonS3>> | External system to integrate with Snowflake |  | x
|===

[[MicrosoftAzure]]
=== Microsoft Azure

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Url a| String | URL for the Microsoft Azure. |  | x
| Microsoft Azure Storage Integration Credentials a| One of:

* <<MicrosoftAzureStorageIntegration>>
* <<MicrosoftAzureKeyCredentials>>
* <<MicrosoftAzureNoCredentials>> | Security credentials for connecting to Microsoft Azure. |  | x
| Encryption a| One of:

* <<AzureCse>> | Required only for loading from or unloading into encrypted files; not required if storage location and files are unencrypted. |  |
|===

[[GoogleCloudStorage]]
=== Google Cloud Storage

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Url a| String | URL for the Google Cloud Storage. |  | x
| Storage Integration Name a| String | Name of the storage integration used to delegate authentication responsibility for external cloud storage. |  | x
| Encryption a| One of:

* <<GcsSseMks>> | Required only for loading from/unloading into encrypted files; not required if storage location and files are unencrypted. |  |
|===

[[AmazonS3]]
=== Amazon S3

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Url a| String | URL for the Amazon S3. |  | x
| Amazon S3 Storage Integration Credentials a| One of:

* <<AmazonS3StorageIntegration>>
* <<AmazonS3KeyCredentials>>
* <<AmazonS3RoleCredentials>>
* <<AmazonS3NoCredentials>> | The security credentials for connecting to AWS and accessing the private/protected S3 bucket where the files to load/unload are staged. |  | x
| Encryption a| One of:

* <<AwsCse>>
* <<AwsSseS3>>
* <<AwsSseKms>> | Required only for loading from/unloading into encrypted files; not required if storage location and files are unencrypted. |  |
|===

[[AwsCse]]
=== AWS CSE

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Master Key a| String | Specifies the client-side master key used to encrypt the files in the bucket. The master key must be a 128-bit or 256-bit key in Base64-encoded form.
 Client-side encryption (requires a MASTER_KEY value). Currently, the client-side master key you provide can only be a symmetric key. |  | x
|===

[[AwsSseKms]]
=== Aws Sse Kms

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Kms Key Id a| String | Optionally specifies the ID for the AWS KMS-managed key used to encrypt files unloaded into the bucket. If no value is provided, your default KMS key ID is used to encrypt files on unload.
 Note that this value is ignored for data loading. |  |
|===

[[GcsSseMks]]
=== Gcs Sse Mks

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Kms Key Id a| String | Key for Gcs Sse Mks encryption algorithm. |  |
|===

[[AzureCse]]
=== Azure Cse

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Master Key a| String | Specifies the client-side master key used to encrypt files. The master key must be a 128-bit or 256-bit key in Base64-encoded form. |  | x
|===

[[AmazonS3StorageIntegration]]
=== Amazon S3 Storage Integration

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Storage Integration Name a| String | Name of the storage integration used to delegate authentication responsibility for external cloud storage. |  | x
|===

[[AmazonS3KeyCredentials]]
=== Amazon S3 Key Credentials

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Aws Key Id a| String | AWS Key Id. |  | x
| Aws Key Secret a| String | AWS Key Secret. |  | x
| Aws Token a| String | AWS Token. |  |
|===

[[AmazonS3RoleCredentials]]
=== Amazon S3 Role Credentials

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Aws Role a| String | AWS Role. |  | x
|===

[[MicrosoftAzureStorageIntegration]]
=== Microsoft Azure Storage Integration

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Storage Integration Name a| String | Name of the storage integration used to delegate authentication responsibility for external cloud storage. |  | x
|===

[[MicrosoftAzureKeyCredentials]]
=== Microsoft Azure Key Credentials

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Azure Sas Token a| String | Specifies the SAS (shared access signature) token for connecting to Azure and accessing the private container where the files containing data are staged. Credentials are generated by Azure. |  | x
|===

[[table]]
=== Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Table Name a| String | Specifies the name of the table from which data is unloaded. |  | x
|===

[[query]]
=== Query

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Sql a| String | SELECT statement that returns data to be unloaded into files. You can limit the number of rows returned by specifying a LIMIT / FETCH clause in the query. |  | x
| Validation Mode a| Boolean | Execute COPY in validation mode to return the result of a query and view the data that will be unloaded from the orderstiny table if COPY is executed in normal mode:
 copy into @my_stage
 from (select * from orderstiny limit 5)
 validation_mode='RETURN_ROWS'; | false |
|===

[[DefinitionByNameForCopyIntoLocation]]
=== Definition By Name For Copy Into Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| File Format Name a| String | Specifies an existing named file format to use for unloading data from the table.
 The named file format determines the format type (CSV, JSON, PARQUET), as well as any other format options, for the data files. |  | x
|===

[[DefinitionByTypeForCopyIntoLocation]]
=== Definition By Type For Copy Into Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| File Format Options For Copy Into Location a| One of:

* <<CsvForCopyIntoLocation>>
* <<JsonForCopyIntoLocation>>
* <<ParquetForCopyIntoLocation>> | Specifies the type of files unloaded from the table.
 If a format type is specified, additional format-specific options can be specified. |  | x
|===

[[CsvForCopyIntoLocation]]
=== Csv For Copy Into Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Record Delimiter a| String | One or more single-byte or multibyte characters that separate records in an input file or unloaded file. |  |
| Field Delimiter a| String | One or more single-byte or multibyte characters that separate fields in an input file or unloaded file. |  |
| File Extension a| String | String that specifies the extension for files unloaded to a stage. Accepts any extension. The user is responsible for specifying a valid file extension that can be read by the desired software or service. |  |
| Date Format a| String |  | Auto |
| Time Format a| String |  | Auto |
| Timestamp Format a| String |  | Auto |
| Binary Format a| Enumeration, one of:

** HEX
** BASE64
** UTF8 |  | HEX |
| Escape Character a| String |  | NONE |
| Escape Unenclosed Field Character a| String |  |  |
| Field Optionally Enclosed By a| String |  | NONE |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first one to convert to from SQL NULL. |  |
| Empty Field As Null a| Boolean | Used in combination with emptyFieldAsNull when set as false allows empty strings to be loaded in tables without enclosing the field values in quotes. | true |
|===

[[JsonForCopyIntoLocation]]
=== Json For Copy Into Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| File Extension a| String |  |  |
|===

[[ParquetForCopyIntoLocation]]
=== Parquet For Copy Into Location

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** LZO
** SNAPPY
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
|===

[[DefinitionByNameForCopyIntoTable]]
=== Definition By Name For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| File Format Name a| String | Specifies an existing named file format to use for loading data into the table.
 The named file format determines the format type (CSV, JSON, PARQUET), as well as any other format options, for the data files. |  | x
|===

[[DefinitionByTypeForCopyIntoTable]]
=== Definition By Type For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| File Format Options For Copy Into Table a| One of:

* <<AvroForCopyIntoTable>>
* <<CsvForCopyIntoTable>>
* <<JsonForCopyIntoTable>>
* <<OrcForCopyIntoTable>>
* <<ParquetForCopyIntoTable>>
* <<XmlForCopyIntoTable>> | Specifies the type of files loaded into the table.
 If a format type is specified, additional format-specific options can be specified. |  | x
|===

[[AvroForCopyIntoTable]]
=== Avro For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first one to convert to from SQL NULL. |  |
|===

[[CsvForCopyIntoTable]]
=== Csv For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Record Delimiter a| String | One or more single-byte or multibyte characters that separate records in an input file or unloaded file. |  |
| Field Delimiter a| String | One or more single-byte or multibyte characters that separate records in an input file or unloaded file. |  |
| Skip Header Count a| Number |  | 0 |
| Skip Blank Lines a| Boolean | Specifies whether to skip any blank lines encountered in data, instead of resulting in an end-of-record error. | false |
| Date Format a| String |  | Auto |
| Time Format a| String |  | Auto |
| Timestamp Format a| String |  | Auto |
| Binary Format a| Enumeration, one of:

** HEX
** BASE64
** UTF8 |  | HEX |
| Escape Character a| String |  |  |
| Escape Unenclosed Field Character a| String | Specifies a single character used as the escape character for unenclosed field values only. |  |
| Trim Space a| Boolean |  | false |
| Field Optionally Enclosed By a| String |  |  |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first one to convert to from SQL NULL. |  |
| Error On Column Count Mismatch a| Boolean | Specifies whether to generate a parsing error if the number of delimited columns (i.e. fields) in an input file does not match the number of columns in the corresponding table. | true |
| Replace Invalid Characters a| Boolean | Specifies whether to replace invalid UTF-8 characters with a default Unicode character instead of resulting in an error. | false |
| Validate UTF8 a| Boolean |  | true |
| Empty Field As Null a| Boolean | Used in combination with emptyFieldAsNull when set as false allows empty strings to be loaded in tables without enclosing the field values in quotes. | true |
| Skip Byte Order Mark a| Boolean | Specifies whether to skip any byte order mark information from input files so that they wouldn't cause errors or be merged into the first table column. | true |
| Encoding a| Enumeration, one of:

** BIG5
** EUCJP
** EUCKR
** GB18030
** IBM420
** IBM424
** ISO2022CN
** ISO2022JP
** ISO2022KR
** ISO88591
** ISO88592
** ISO88595
** ISO88596
** ISO88597
** ISO88598
** ISO88599
** KOI8R
** SHIFTJIS
** UTF8
** UTF16
** UTF16BE
** UTF16LE
** UTF32
** UTF32BE
** UTF32LE
** WINDOWS1250
** WINDOWS1251
** WINDOWS1252
** WINDOWS1253
** WINDOWS1254
** WINDOWS1255
** WINDOWS1256 |  | UTF8 |
|===

[[JsonForCopyIntoTable]]
=== Json For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Date Format a| String |  | Auto |
| Time Format a| String |  | Auto |
| Timestamp Format a| String |  | Auto |
| Binary Format a| Enumeration, one of:

** HEX
** BASE64
** UTF8 |  | HEX |
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first one to convert to from SQL NULL. |  |
| Enable Octal a| Boolean |  | false |
| Allow Duplicate a| Boolean |  | false |
| Strip Outer Array a| Boolean |  | false |
| Strip Null Values a| Boolean | Specifies that the JSON parser should remove object fields or array elements containing null values. | false |
| Ignore UTF8 Errors a| Boolean | Specifies whether to suppress UTF-8 encoding errors and silently replace with a default Unicode character. | false |
| Skip Byte Order Mark a| Boolean | Specifies whether to skip any byte order mark information from input files so that they wouldn't cause errors or be merged into the first table column. | true |
|===

[[OrcForCopyIntoTable]]
=== Orc For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first one to convert to from SQL NULL. |  |
|===

[[ParquetForCopyIntoTable]]
=== Parquet For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** SNAPPY
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Binary As Text a| Boolean | Specifies whether to interpret columns with no defined logical data type as UTF-8 text when set to True, or binary data when set to False. | true |
| Trim Space a| Boolean |  | false |
| Null Ifs a| Array of String | Specifies a list of values from which Snowflake selects the first one to convert to from SQL NULL. |  |
|===

[[XmlForCopyIntoTable]]
=== Xml For Copy Into Table

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Compression a| Enumeration, one of:

** AUTO
** GZIP
** BZ2
** BROTLI
** ZSTD
** DEFLATE
** RAW_DEFLATE
** NONE | Specifies a compression algorithm to use for compressing the unloaded data files. | AUTO |
| Ignore UTF8 Errors a| Boolean | Specifies whether to suppress UTF-8 encoding errors and silently replace with a default Unicode character. | false |
| Preserve Space a| Boolean | Specifies whether the XML parser preserves leading and trailing spaces in element content. | false |
| Strip Outer Element a| Boolean | Specifies whether the XML parser strips out the outer XML element, exposing 2nd level elements as separate documents. | false |
| Disable Snowflake Data a| Boolean | Specifies whether the XML parser disables recognition of Snowflake semi-structured data tags. | false |
| Disable Auto Convert a| Boolean | Specifies whether the XML parser disables automatic conversion of numeric and Boolean values from text to native representation. | false |
| Skip Byte Order Mark a| Boolean | Specifies whether to skip any byte order mark information from input files so that they wouldn't cause errors or be merged into the first table column. | true |
|===

[[Conditional]]
=== Conditional

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Execution Mode a| Enumeration, one of:

** ALL
** FIRST |  |  | x
| Conditions a| Array of <<ConditionStatement>> |  |  | x
| Else Into Clause a| String |  |  |
| Overwrite a| Boolean |  | false |
| Subquery a| String |  |  | x
|===

[[ConditionStatement]]
=== Condition Statement

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| When Condition a| String |  |  | x
| Into Clauses a| Array of String |  |  | x
|===

[[Unconditional]]
=== Unconditional

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Into Clauses a| Array of String |  |  | x
| Overwrite a| Boolean |  | false |
| Subquery a| String |  |  | x
|===

[[NotMatchedInsertClause]]
=== Not Matched Insert Clause

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Column Names a| Array of String |  |  |
| Column Values a| Array of String |  |  | x
| Case Predicate a| String |  |  |
|===

[[MatchedUpdateClause]]
=== Matched Update Clause

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Update Expression a| String |  |  | x
| Case Predicate a| String |  |  |
|===

[[MatchedDeleteClause]]
=== Matched Delete Clause

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Case Predicate a| String |  |  |
|===
