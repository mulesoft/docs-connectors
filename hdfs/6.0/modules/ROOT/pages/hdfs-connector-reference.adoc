= HDFS (Hadoop) Connector Reference - Mule 4
:page-aliases: connectors::hdfs/hdfs-connector-reference.adoc

Support Category: https://www.mulesoft.com/legal/versioning-back-support-policy#anypoint-connectors[Select]

Anypoint Connector for Hadoop (HDFS) v6.0

Release Notes: xref:release-notes::connector/hdfs-connector-release-notes-mule-4.adoc[Hadoop (HDFS) Connector Release Notes]


[[hdfs]]
== HDFS Configurations

=== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
|Name | String | The name for this configuration. Connectors reference the configuration with this name. | | x
| Connection a| * <<hdfs_kerberos, Kerberos>>
* <<hdfs_simple, Simple>>
 | The connection types to provide to this configuration. | | x
| Expiration Policy a| <<ExpirationPolicy>> |  Configures the minimum amount of time that a dynamic configuration instance can remain idle before Mule considers it eligible for expiration. This does not mean that the platform expires the instance at the exact moment that it becomes eligible. Mule purges the instances as appropriate. |  |
|===

[[connection_types]]
== Connection Types

To access the data in a Hadoop (HDFS) instance, you must authenticate your applicationâ€™s requests using a supported authentication method.

For Hadoop (HDFS) Connector, the following connection authentication types are supported:

* <<hdfs_kerberos,Kerberos>>
* <<hdfs_simple,Simple>>

[[hdfs_kerberos]]
=== Kerberos

Use the following fields in the Global Element Properties dialog window to configure the *Kerberos* connection type:

[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Username a| String |  The Kerberos principal. The Username is passed to the HDFS client as the `hadoop.job.ugi` configuration entry. The Username can be overriden by values you specify in *Configuration Resources* and *Configuration Entries*. This parameter is called Username for backward compatibility reasons. |  |
| Keytab Path a| String | Enter the path to the https://web.mit.edu/kerberos/krb5-1.12/doc/basic/keytab_def.html[keytab file] associated with the Username you specified. The path is used to obtain a ticket granting ticket (TGT) from the authorization server. If this value is not provided Kerberos looks for a TGT associated with the specified Username within your local Kerberos cache. |  |
| Name Node Uri a| String |  The name of the file system to connect to. The Name Node is passed to the HDFS client as the `FileSystem#FS_DEFAULT_NAME_KEY` configuration entry. The Name Node can be overriden by values you specify in *Configuration Resources* and *Configuration Entries*. |  | x
| Configuration Resources a| Array of String |  A `java.util.List` of configuration resource files for the HDFS client to load. You can provide additional configuration files, for example, `core-site.xml`. |  |
| Configuration Entries a| Object |  A `java.util.Map` of configuration entries to use by the HDFS client. You can provide additional configuration entries as key-value pairs. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If reconnection is enabled, deployment fails if the test doesn't pass after exhausting the associated reconnection strategy. |  |
|===

[[hdfs_simple]]
=== Simple

Use the following fields in the Global Element Properties dialog window to configure the *Simple* connection type:

[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Username a| String |  User identity that Hadoop uses for permissions in HDFS. When Simple authentication is used, Hadoop requires that the user is set as a system property called `HADOOP_USER_NAME`. If a value is not provided, Hadoop uses the username of the OS user who is currently logged in. |  |
| Name Node Uri a| String |  The name of the file system to which to connect. The Name Node is passed to the HDFS client as the `FileSystem#FS_DEFAULT_NAME_KEY` configuration entry. The Name Node can be overriden by values you specify in *Configuration Resources* and *Configuration Entries*. |  | x
| Configuration Resources a| Array of String |  A `java.util.List` of configuration resource files for the HDFS client to load. You can provide additional configuration files, for example, `core-site.xml`. |  |
| Configuration Entries a| Object |  A `java.util.Map` of configuration entries for the HDFS client to use. You can provide additional configuration entries as key-value pairs. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If reconnection is enabled, deployment fails if the test doesn't pass after exhausting the associated reconnection strategy. |  |
|===

== Operations

* <<append>>
* <<copyFromLocalFile>>
* <<copyToLocalFile>>
* <<deleteDirectory>>
* <<deleteFile>>
* <<getMetadata>>
* <<globStatus>>
* <<listStatus>>
* <<makeDirectories>>
* <<readOperation>>
* <<rename>>
* <<setOwner>>
* <<setPermission>>
* <<write>>

=== Associated Sources
* <<read>>


[[append]]
=== Append
`<hdfs:append>`

Append the current payload to a file located at the designated path. *Note:* by default the Hadoop server has the append option disabled. To append data to an existing file, refer to the dfs.support.append configuration parameter.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path of the file to write to. |  | x
| Buffer Size a| Number |  The buffer size to use when appending to the file. |  4096 |
| Payload a| Binary |  The payload to append to the file. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===


=== For Configurations
<<hdfs>>

==== Throws

* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[copyFromLocalFile]]
=== Copy From Local File
`<hdfs:copy-from-local-file>`


Copy the source file on the local disk to the file system for a target path, set *Delete Source* if the source file should be removed.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Delete Source a| Boolean |  Whether to delete the source. |  false |
| Overwrite a| Boolean |  Whether to overwrite destination content. |  true |
| Source a| String |  The source path in the file system. |  | x
| Destination a| String |  The target path on the local disk. |  | x
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===


=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[copyToLocalFile]]
=== Copy To Local File
`<hdfs:copy-to-local-file>`

Copy the source file in the file system to a local disk at the given target path. Set *Delete Source* if the source file should be removed. *Use Raw Local File System* indicates whether to use RawLocalFileSystem as it is a non-CRC file system.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Delete Source a| Boolean |  Whether to delete the source. |  false |
| Use Raw Local File System a| Boolean |  Whether to use RawLocalFileSystem as a local file system. |  false |
| Source a| String |  The source path on the File System. |  | x
| Destination a| String |  The target path on the local disk. |  | x
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===


=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[deleteDirectory]]
=== Delete Directory
`<hdfs:delete-directory>`


Delete the file or directory located at the designated path.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path of the file to delete. |  | x
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===


=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[deleteFile]]
=== Delete File
`<hdfs:delete-file>`


Delete the file or directory located at the designated path.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path of the file to delete. |  | x
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===


=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[getMetadata]]
=== Get Metadata
`<hdfs:get-metadata>`


Get the metadata of a path


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path of the file to delete. |  | x
| Target Variable a| String |  The name of a variable to store the operation's output. |  |
| Target Value a| String |  An expression to evaluate against the operation's output and store the expression outcome in the target variable. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |<<MetaData>>
|===

=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[globStatus]]
=== Glob Status
`<hdfs:glob-status>`


Return all the files that match file pattern and are not checksum files. Results are sorted by their names.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path Pattern a| String |  A regular expression specifying the path pattern. |  | x
| Filter a| String |  The user supplied path filter |  |
| Target Variable a| String |  The name of a variable to store the operation's output. |  |
| Target Value a| String |  An expression to evaluate against the operation's output and store the expression outcome in the target variable. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of <<FileStatus>>
|===

=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:RETRY_EXHAUSTED


[[listStatus]]
=== List Status
`<hdfs:list-status>`


List the statuses of the files and directories in the given path if the path is a directory.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The given path |  | x
| Filter a| String |  The user supplied path filter |  |
| Target Variable a| String |  The name of a variable to store the operation's output. |  |
| Target Value a| String |  An expression to evaluate against the operation's output and store the expression outcome in the target variable. |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Array of <<FileStatus>>
|===

=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN

[[makeDirectories]]
=== Make Directories
`<hdfs:make-directories>`

Make the given file and all non-existent parents into directories. Has the semantics of Unix 'mkdir -p'. Existence of the directory hierarchy is not an error.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path to create one or more directories. |  | x
| Permission a| String |  The file system permission to use when creating the directories, either in octal or symbolic format (umask). |  |
| Reconnection Strategy a|* <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===


=== For Configurations

<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[readOperation]]
=== Read Operation
`<hdfs:read-operation>`


Read the content of a file designated by its path and streams it to the rest of the flow.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path of the file to read. |  | x
| Buffer Size a| Number |  The buffer size to use when reading the file. |  4096 |
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* non-repeatable-stream |  Configure if repeatable streams should be used and their behavior |  |
| Target Variable a| String |  The name of a variable to store the operation's output. |  |
| Target Value a| String |  An expression to evaluate against the operation's output and store the expression outcome in the target variable |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Binary
|===

=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[rename]]
=== Rename
`<hdfs:rename>`

Renames path target to path destination.

==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Source a| String |  The source path to be renamed. |  | x
| Destination a| String |  New path after rename. |  | x
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

=== For Configurations

<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[setOwner]]
=== Set Owner
`<hdfs:set-owner>`


Set owner of a path for a file or a directory. The Omnername and Groupname cannot both be null.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path of the file or directory to set owner. |  | x
| Ownername a| String |  If it is null, the original username remains unchanged. |  | x
| Groupname a| String |  If it is null, the original groupname remains unchanged. |  | x
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===


=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[setPermission]]
=== Set Permission
`<hdfs:set-permission>`


Set permission of a path, that is, for a file or a directory.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  The path of the file or directory to set permission. |  | x
| Permission a| String |  The file system permission to be set. |  | x
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===


=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


[[write]]
=== Write
`<hdfs:write>`


Write the current payload to the designated path, either creating a new file or appending to an existing one.


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Payload a| Binary |  the payload to write to the file. |  #[payload] |
| Path a| String |  The path of the file to write to. |  | x
| Permission a| String |  The file system permission to use if a new file is created, either in octal or symbolic format (umask). |  700 |
| Overwrite a| Boolean |  If a pre-existing file should be overwritten with the new content. |  true |
| Buffer Size a| Number |  The buffer size to use when appending to the file. |  4096 |
| Replication a| Number |  Block replication for the file. |  1 |
| Block Size a| Number |  The buffer size to use when appending to the file. |  1048576 |
| Owner User Name a| String |  The username owner of the file. |  |
| Owner Group Name a| String |  The group owner of the file. |  |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===


=== For Configurations
<<hdfs>>

==== Throws
* HDFS:CONNECTIVITY
* HDFS:INVALID_REQUEST_DATA
* HDFS:INVALID_STRUCTURE_FOR_INPUT_DATA
* HDFS:RETRY_EXHAUSTED
* HDFS:UNKNOWN


== Sources

[[read]]
=== Read
`<hdfs:read>`


==== Parameters
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Path a| String |  Read the content of a file designated by its path |  | x
| Buffer Size a| Number |  |  4096 |
| Primary Node Only a| Boolean |  Whether this source should be executed only on the primary node when running in a cluster. |  |
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* non-repeatable-stream |  Configure if repeatable streams should be used and their behavior |  |
| Redelivery Policy a| <<RedeliveryPolicy>> |  Defines a policy for processing the redelivery of the same message. |  |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  |
|===

==== Output
[%autowidth.spread]
|===
|Type |Any
| Attributes Type a| Any
|===

=== For Configurations
<<hdfs>>

== Types
[[Reconnection]]
=== Reconnection

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Fails Deployment a| Boolean | When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment fails if the test doesn't pass after exhausting the associated reconnection strategy. |  |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> | The reconnection strategy to use. |  |
|===

[[reconnect]]
=== Reconnect

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often to reconnect (in milliseconds) | |
| Count a| Number | The number of reconnection attempts to make | |
| blocking |Boolean |If false, the reconnection strategy runs in a separate, non-blocking thread. |true |
|===

[[reconnect-forever]]
=== Reconnect Forever

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often in milliseconds to reconnect | |
| blocking |Boolean |If false, the reconnection strategy runs in a separate, non-blocking thread. |true |
|===

[[ExpirationPolicy]]
=== Expiration Policy

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Max Idle Time a| Number | A scalar time value for the maximum amount of time a dynamic configuration instance should be allowed to be idle before it's considered eligible for expiration. |  |
| Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS | A time unit that qualifies the maxIdleTime attribute |  |
|===

[[repeatable-in-memory-stream]]
=== Repeatable In Memory Stream

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Initial Buffer Size a| Number | The amount of memory that will be allocated to consume the stream and provide random access to it. If the stream contains more data than can be fit into this buffer, then the buffer expands according to the bufferSizeIncrement attribute, with an upper limit of maxInMemorySize. |  |
| Buffer Size Increment a| Number | This is by how much the buffer size expands if it exceeds its initial size. Setting a value of zero or lower means that the buffer should not expand, meaning that a STREAM_MAXIMUM_SIZE_EXCEEDED error is raised when the buffer gets full. |  |
| Max Buffer Size a| Number | The maximum amount of memory to use. If more than that is used, the STREAM_MAXIMUM_SIZE_EXCEEDED error is raised. A value lower than or equal to zero means no limit. |  |
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which all these attributes are expressed |  |
|===

[[repeatable-file-store-stream]]
=== Repeatable File Store Stream

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Max In Memory Size a| Number | Defines the maximum memory that the stream should use to keep data in memory. If more memory is consumed, content on the disk is buffered. |  |
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which maxInMemorySize is expressed. |  |
|===

[[RedeliveryPolicy]]
=== Redelivery Policy

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Max Redelivery Count a| Number | The maximum number of times a message can be redelivered and processed unsuccessfully before triggering a process-failed message. |  |
| Use Secure Hash a| Boolean | Whether to use a secure hash algorithm to identify a redelivered message. |  |
| Message Digest Algorithm a| String | The secure hashing algorithm to use. If not set, the default is SHA-256. |  |
| Id Expression a| String | Defines one or more expressions to use to determine when a message has been redelivered. This property can only be set if *Use Secure Hash* is false. |  |
| Object Store a| Object Store | The object store where the redelivery counter for each message is stored. |  |
|===

[[MetaData]]
=== Metadata

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Check Summary a| <<CheckSummary>> |  |  |
| Content Summary a| <<ContentSummary>> |  |  |
| File Status a| <<FileStatus>> |  |  |
| Path Exists a| Boolean |  |  |
|===

[[CheckSummary]]
=== Check Summary

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Bytes Per CRC a| Number |  |  |
| Crc Per Block a| Number |  |  |
| Md5 a| String |  |  |
|===

[[ContentSummary]]
=== Content Summary

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Directory Count a| Number |  |  |
| File Count a| Number |  |  |
| Length a| Number |  |  |
| Snapshot Directory Count a| Number |  |  |
| Snapshot File Count a| Number |  |  |
| Snapshot Length a| Number |  |  |
| Snapshot Space Consumed a| Number |  |  |
|===

[[FileStatus]]
=== File Status

[%header,cols="20s,25a,30a,15a,10a"]
|===
| Field | Type | Description | Default Value | Required
| Access Time a| Number |  |  |
| Block Replication a| Number |  |  |
| Block Size a| Number |  |  |
| Directory a| Boolean |  |  |
| Group a| String |  |  |
| Length a| Number |  |  |
| Modification Time a| Number |  |  |
| Owner a| String |  |  |
| Path a| String |  |  |
| Permission a| String |  |  |
| Symbolic Link a| Boolean |  |  |
|===

== See Also

https://help.mulesoft.com[MuleSoft Help Center]
