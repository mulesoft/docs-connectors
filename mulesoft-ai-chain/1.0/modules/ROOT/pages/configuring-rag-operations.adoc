= Configuring RAG Operations

"RAG" stands for Retrieval-Augmented Generation, which combines the retrieval of relevant documents with the generation of responses. This technique enhances the performance of language models by providing them with specific context or background information from the retrieved documents, enabling them to generate more informed and accurate responses.

== Configure the RAG Load Document Operation

The *RAG load document* operation retrieves information based on a plain text prompt from an in-memory embedding store. 

To configure the *RAG load document* operation:

. Select the operation on the Studio canvas.
. In the *General* properties section, configure these fields:
* Data
+
The prompt to send to the LLM and the embedding store to respond to.
* Context Path +
Contains the full file path for the document to ingest into the embedding store. Ensure the file path is accessible. 
+
You can also use a DataWeave expression for this field, for example: 
+
`mule.home ++ "/apps/" ++ app.name ++ "/customer-service.pdf"`
. In the *Context* section for the operation, select the *File Type*:
* *text* 
+
Text files, such as JSON, XML, TXT, and CSV
* *url* 
+
A single URL pointing to web content to ingest.

This is the XML configuration for this operation:

[[source,xml]]
----
<ms-aichain:rag-load-document 
  doc:name="RAG load document" 
  doc:id="3d3edd66-4970-4dad-a5bf-2a8eae123da4" 
  config-ref="MAC_AI_Llm_configuration" 
  data="#[payload.prompt]" 
  contextPath="#[payload.contextPath]"
/>
----

== Output Configuration

This operation responds with a JSON payload that contains the main LLM response. Additionally, attributes such as token usage are included as part of the metadata (attributes), but not within the main payload.

This is an example response of the JSON payload:

[source,json]
----
{
  "response": "Wakanda, a technologically advanced and environmentally conscious nation in Africa, is renowned for its unique integration of ancient traditions with cutting-edge innovations, powered by the rare metal Vibranium. With a population of 12.5 million, it emphasizes sustainable growth, quality education, and healthcare, while maintaining a zero carbon footprint through advanced eco-tech solutions. Despite its peaceful nature, Wakanda's formidable military and cultural heritage, led by King Tâ€™Challa and the Dora Milaje, ensure its resilience and unity as a symbol of progress and tradition."
}
----

The operation also returns attributes that aren't within the main JSON payload, which include information about token usage, for example:

[source,json]
----
{
  "tokenUsage": {
      "outputCount": 9, 
      "totalCount": 18, 
      "inputCount": 9 
  },
  "additionalAttributes": {}
}
----

* `tokenUsage` 
+
Token usage metadata returned as attributes
* `outputCount` 
+
Number of tokens used to generate the output
* `totalCount` Total number of tokens used for input and output
* `inputCount` 
+
Number of tokens used to process the input

== Example Use Cases

This operation is useful when you need to retrieve information from a document based on a plain text prompt, such as for:

* Knowledge Management
+
Extract specific information from documents stored in a knowledge base.
* Customer Support 
+
Retrieve relevant data from customer service documents to assist with inquiries.
* Research
+
Accessing information from research papers or documents based on specific queries.

== See Also

* xref:connectors::introduction/introduction-to-anypoint-connectors.adoc[Introduction to Anypoint Connectors]
* xref:mulesoft-ai-chain-connector-reference.adoc[]
* https://help.mulesoft.com[MuleSoft Help Center]
