= MuleSoft AI Chain - Additional Configuration Information - Mule 4

MuleSoft AI Chain Connector supports 15 operations, categorized into:

* Agent
* Chat
* Embeddings
* Image generation
* RAG
* Sentiment
* Tools 

[[agent-operations]]
== Agent Define Prompt

The *Agent define prompt template* operation is essential for using specific prompt templates with your LLMs. This operation helps you define and compose AI functions using plain text. This enables the creation of natural language prompts, generating responses, extracting information, invoking other prompts, or performing any text-based task.

=== Configure the Agent Define Prompt

To configure the *Agent define prompt* operation:

. In the *General* properties tab for the operation, enter the following information:
* Dataset
+
Specify the dataset for the LLM to evaluate using the provided template and instructions.
* Template
+
Enter the prompt template for the operation.
* Instructions
+
Provide the instructions for the LLM, outlining the goals of the task.
+
This is the XML for this operation:
+
[source,xml,linenums, subs=attributes+]
----
<ms-chainai:agent-define-prompt-template 
  doc:name="Agent define prompt template" 
  doc:id="f1c29c39-eac9-468c-9c46-4109a66303ec" 
  config-ref="MuleChain_AI_Llm_configuration" 
  template="#[payload.template]" 
  instructions="#[payload.instructions]" 
  dataset="#[payload.dataset]"
/>
----

=== Output Configuration

This operation responds with a JSON payload containing the main LLM response. Additionally, attributes such as token usage are included as part of the metadata (attributes) but not within the main payload.

This is an example response:

[source,json]
----
{
  "response": "{\n  \"type\": \"positive\",\n  \"response\": \"Thank you for your positive feedback on the training last week. We are glad to hear that you had a great experience. Have a nice day!\"\n}"
}
----

Along with the JSON payload, the operation returns attributes, which include information about token usage, for example:

[source,json]
----
{
  "tokenUsage": {
      "outputCount": 9,
      "totalCount": 18,
      "inputCount": 9
  },
  "additionalAttributes": {}
}
----

\\annotate the code
tokenUsage: The token usage metadata returned as attributes.
outputCount: The number of tokens used to generate the output.
totalCount: The total number of tokens used for input and output.
inputCount: The number of tokens used to process the input.

[[chat-operations]]
== Chat Operations

=== Configure the Chat Answer Prompt Operation

The *Chat answer prompt* operation is a simple prompt request operation to the configured LLM. It uses a plain text prompt as input and responds with a plain text answer.

To configure the *Chat answer prompt* operation:

. In the *General* properties tab for the operation, enter plain text for the *Prompt*.

This is the XML configuration for this operation:

[[source,xml]]
----
<ms-chainai:chat-answer-prompt 
  doc:name="Chat answer prompt" 
  doc:id="8ba9d534-f801-4ac7-8a31-11462fc5204b" 
  config-ref="MuleChain_AI_Llm_configuration" 
  prompt="#[payload.prompt]"  
/>
----

[[output-config]]
==== Output Configuration

This operation responds with a JSON payload containing the main LLM response. Additionally, token usage and other metadata are returned as attributes.

This is an example response:

[source,json]
----
{
    "response": "The capital of Switzerland is Bern. It's known for its well-preserved medieval old town, which is a UNESCO World Heritage site. Bern became the capital of Switzerland in 1848. The Swiss parliament, the Federal Assembly, is located in Bern."
}
----

Along with the JSON payload, the operation returns attributes, which include information about token usage, for example:

[source,json]
----
{
  "tokenUsage": {
      "outputCount": 9,
      "totalCount": 18,
      "inputCount": 9
  },
  "additionalAttributes": {}
}
----

=== Configure the Chat Answer Prompt With Memory Operation

The *Chat answer prompt with memory* operation is useful for retaining conversation history for a multi-user chat operation.

To configure the *Chat answer prompt with memory* operation:

. In the *General* properties tab for the operation, enter the following:
* *Data*
+
Contains the prompt for the operation.
* *Memory Name*
+
Name of the conversation. For multi-user support, enter the unique user ID.
* *DB File Path* 
+
Path to the in-memory database for storing the conversation history. 
+
You can also use a DataWeave expression for this field, for example: 
+
`#["/Users/john.wick/Desktop/mac-demo/db/" ++ payload.memoryName].`
* Max Messages
+
Maximum number of messages to remember for the conversation defined in *Memory Name*.

This is the XML configuration for this operation:

[[source,xml]]
----
<ms-aichain:chat-answer-prompt-with-memory
  doc:name="Chat answer prompt with memory"
  doc:id="7e62e70e-eff7-4080-bb20-3d162bb84c39"
  config-ref="MuleSoft_AI_Chain_Config"
  memoryName="#[payload.memoryName]"
  dbFilePath='#["/Users/john.wick/Desktop/mac-demo/db/" ++ payload.memoryName]'
  maxMessages="#[payload.maxMessages]">
  <ms-aichain:data><![CDATA[#[payload.prompt]]]></ms-aichain:data>
</ms-aichain:chat-answer-prompt-with-memory>
----

==== Output Configuration

This operation responds with a JSON payload containing the main LLM response, with additional metadata stored in attributes.

This is an example response:

[source,json]
----
{
    "response": "I'm sorry, I do not have access to personal information such as your name."
}
----

Along with the JSON payload, the operation returns attributes, which include information about token usage, for example:

[source,json]
----
{
  "tokenUsage": {
    "outputCount": 13,
    "totalCount": 44,
    "inputCount": 31
  },
  "additionalAttributes": {
    "memoryName": "memory",
    "maxMessages": "2",
    "dbFilePath": "/.../memory.db"
  }
}
----

=== Configure the 












[[embeddings-operations]]
== Embeddings Operations

[[image-generation-operations]]
== Image Generation Operations

[[rag-operations]]
== RAG Operations

[[sentiment-operations]]
== Sentiment Operations

[[tools-operations]]
== Tools Operations

== Next Step

After you complete configuring the connector, you can try the xref:connector-template-files-connector-examples.adoc[Examples].

== See Also

* xref:connectors::introduction/introduction-to-anypoint-connectors.adoc[Introduction to Anypoint Connectors]
* https://help.mulesoft.com[MuleSoft Help Center]
