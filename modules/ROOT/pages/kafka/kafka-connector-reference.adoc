= Apache Kafka Module Documentation Reference
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

== Configurations
---
[[kafka-consumer-config]]
=== Consumer configuration


==== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
|Name | String | The name for this configuration. Connectors reference the configuration with this name. | | x
| Connection a| * <<kafka-consumer-config_basic-kafka-consumer-connection, Kafka Basic Consumer Connection>>
* <<kafka-consumer-config_kerberos-kafka-consumer-connection, Kafka Kerberos Consumer Connection>>
* <<kafka-consumer-config_kerberos-ssl-kafka-consumer-connection, Kafka Kerbero SSL Consumer Connection>>
* <<kafka-consumer-config_ssl-kafka-consumer-connection, Kafka SSL Consumer Connection>>
 | The connection types that can be provided to this configuration. | | x
| Expiration Policy a| <<ExpirationPolicy>> |  Configures the minimum amount of time that a dynamic configuration instance can remain idle before the runtime considers it eligible for expiration. This does not mean that the platform will expire the instance at the exact moment that it becomes eligible. The runtime will actually purge the instances when it sees it fit. |  |
|===

==== Connection Types
[[kafka-consumer-config_basic-kafka-consumer-connection]]
===== Kafka Basic Consumer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 |
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | x
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
|===
[[kafka-consumer-config_kerberos-kafka-consumer-connection]]
===== Kafka Kerberos Consumer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 |
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | x
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
| Principal a| String |  Kerberos principal |  | x
| Keytab a| String |  Path to keytab file associated with "principal". |  | x
| Service name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | x
| Additional JAAS Properties a| Object |  Additional parperties as key->value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  |
|===
[[kafka-consumer-config_kerberos-ssl-kafka-consumer-connection]]
===== Kafka Kerbero SSL Consumer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 |
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | x
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
| Key Store Type a| String |  The file format of the key store file. This is optional for client. |  JKS |
| Key Store Password a| String |  The store password for the key store file. This is optional for client and only needed if "keyStoreLocation" is configured. |  |
| Key Store Location a| String |  The location of the key store file. This is optional for client and can be used for two-way authentication for client. |  |
| Trust Store Type a| String |  The file format of the trust store file. |  JKS |
| Trust Store Password a| String |  The password for the trust store file. If a password is not set access to the truststore is still available, but integrity checking is disabled. |  | x
| Trust Store Location a| String |  The location of the trust store file. |  | x
| Principal a| String |  Kerberos principal |  | x
| Keytab a| String |  Path to keytab file associated with "principal". |  | x
| Service name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | x
| Additional JAAS Properties a| Object |  Additional parperties as key->value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  |
|===
[[kafka-consumer-config_ssl-kafka-consumer-connection]]
===== Kafka SSL Consumer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 |
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | x
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
| Key Store Type a| String |  The file format of the key store file. This is optional for client. |  JKS |
| Key Store Password a| String |  The store password for the key store file. This is optional for client and only needed if "keyStoreLocation" is configured. |  |
| Key Store Location a| String |  The location of the key store file. This is optional for client and can be used for two-way authentication for client. |  |
| Trust Store Type a| String |  The file format of the trust store file. |  JKS |
| Trust Store Password a| String |  The password for the trust store file. If a password is not set access to the truststore is still available, but integrity checking is disabled. |  | x
| Trust Store Location a| String |  The location of the trust store file. |  | x
|===


==== Associated Sources

* <<consumer>>

---
[[kafka-producer-config]]
=== Producer configuration


==== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
|Name | String | The name for this configuration. Connectors reference the configuration with this name. | | x
| Connection a| * <<kafka-producer-config_basic-kafka-producer-connection, Kafka Basic Producer Connection>>
* <<kafka-producer-config_kerberos-kafka-producer-connection, Kafka Kerberos Producer Connection>>
* <<kafka-producer-config_kerberos-ssl-kafka-producer-connection, Kafka Kerberos SSL Producer Connection>>
* <<kafka-producer-config_ssl-kafka-producer-connection, Kafka SSL Producer Connection>>
 | The connection types that can be provided to this configuration. | | x
| Expiration Policy a| <<ExpirationPolicy>> |  Configures the minimum amount of time that a dynamic configuration instance can remain idle before the runtime considers it eligible for expiration. This does not mean that the platform will expire the instance at the exact moment that it becomes eligible. The runtime will actually purge the instances when it sees it fit. |  |
|===

==== Connection Types
[[kafka-producer-config_basic-kafka-producer-connection]]
===== Kafka Basic Producer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
|===
[[kafka-producer-config_kerberos-kafka-producer-connection]]
===== Kafka Kerberos Producer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
| Principal a| String |  Kerberos principal |  | x
| Keytab a| String |  Path to keytab file associated with "principal". |  | x
| Service name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | x
| Additional JAAS Properties a| Object |  Additional parperties as key->value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  |
|===
[[kafka-producer-config_kerberos-ssl-kafka-producer-connection]]
===== Kafka Kerberos SSL Producer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
| Key Store Type a| String |  The file format of the key store file. This is optional for client. |  JKS |
| Key Store Password a| String |  The store password for the key store file. This is optional for client and only needed if "keyStoreLocation" is configured. |  |
| Key Store Location a| String |  The location of the key store file. This is optional for client and can be used for two-way authentication for client. |  |
| Trust Store Type a| String |  The file format of the trust store file. |  JKS |
| Trust Store Password a| String |  The password for the trust store file. If a password is not set access to the truststore is still available, but integrity checking is disabled. |  | x
| Trust Store Location a| String |  The location of the trust store file. |  | x
| Principal a| String |  Kerberos principal |  | x
| Keytab a| String |  Path to keytab file associated with "principal". |  | x
| Service name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | x
| Additional JAAS Properties a| Object |  Additional parperties as key->value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  |
|===
[[kafka-producer-config_ssl-kafka-producer-connection]]
===== Kafka SSL Producer Connection


====== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). If this property is provided with producer/consumer properties files, this value is ignored and the one from the properties file is used. |  | x
| Additional Properties a| Object |  Additional properties as key->value that you need for your connection. |  |
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
| Key Store Type a| String |  The file format of the key store file. This is optional for client. |  JKS |
| Key Store Password a| String |  The store password for the key store file. This is optional for client and only needed if "keyStoreLocation" is configured. |  |
| Key Store Location a| String |  The location of the key store file. This is optional for client and can be used for two-way authentication for client. |  |
| Trust Store Type a| String |  The file format of the trust store file. |  JKS |
| Trust Store Password a| String |  The password for the trust store file. If a password is not set access to the truststore is still available, but integrity checking is disabled. |  | x
| Trust Store Location a| String |  The location of the trust store file. |  | x
|===

==== Associated Operations
* <<producer>>


[[producer]]
== Producer Operation

`<kafka:producer>`


Operation that facilitates Kafka messages sending into the given topic.


=== Parameters

[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Topic a| String |  Topic to send the message to |  | x
| Key a| String |  Key belonging to the message that is going to be sent |  | x
| Message a| String |  Message to be sent |  #[payload] |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===


=== For Configurations

* <<kafka-producer-config>>

=== Throws

* KAFKA:CONNECTIVITY
* KAFKA:CONNECTIVITY
* KAFKA:UNKNOWN
* KAFKA:RETRY_EXHAUSTED


== Sources

[[consumer]]
== Consumer Operationn

`<kafka:consumer>`


Operation that facilitates Kafka message consumption from a given topic.


=== Parameters

[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Topic a| String |  Name of Kafka topic to consume messages from. |  | x
| Partition Offsets a| Array of <<Offset>> |  Map representing partitions offsets configuration. It has to be in the following format [{"partition_number": "partition_offset"}] (e.g: [{"0":"2"}, [{"1":"5"}]]). |  |
| Redelivery Policy a| <<RedeliveryPolicy>> |  Defines a policy for processing the redelivery of the same message |  |
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* non-repeatable-stream |  Configure if repeatable streams should be used and their behavior |  |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors |  |
|===

=== Output

[cols=".^50%,.^50%"]
|===
| *Type* a| String
| *Attributes Type* a| Any
|===

=== For Configurations

* <<kafka-consumer-config>>



== Types
[[Reconnection]]
=== Reconnection

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Fails Deployment a| Boolean | When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  |
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> | The reconnection strategy to use |  |
|===

[[reconnect]]
=== Reconnect

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often (in ms) to reconnect |  |
| Count a| Number | How many reconnection attempts to make |  |
|===

[[reconnect-forever]]
=== Reconnect Forever

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often (in ms) to reconnect |  |
|===

[[ExpirationPolicy]]
=== Expiration Policy

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Max Idle Time a| Number | A scalar time value for the maximum amount of time a dynamic configuration instance should be allowed to be idle before it's considered eligible for expiration |  |
| Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS | A time unit that qualifies the maxIdleTime attribute |  |
|===

[[Offset]]
=== Offset

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Partition Number a| String |  |  |
| Partition Offset a| String |  |  |
|===

[[RedeliveryPolicy]]
=== Redelivery Policy

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Max Redelivery Count a| Number | The maximum number of times a message can be redelivered and processed unsuccessfully before triggering process-failed-message |  |
| Use Secure Hash a| Boolean | Whether to use a secure hash algorithm to identify a redelivered message |  |
| Message Digest Algorithm a| String | The secure hashing algorithm to use. If not set, the default is SHA-256. |  |
| Id Expression a| String | Defines one or more expressions to use to determine when a message has been redelivered. This property may only be set if useSecureHash is false. |  |
| Object Store a| <<ObjectStore>> | The object store where the redelivery counter for each message is going to be stored. |  |
|===

[[repeatable-in-memory-stream]]
=== Repeatable In Memory Stream

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Initial Buffer Size a| Number | This is the amount of memory that will be allocated in order to consume the stream and provide random access to it. If the stream contains more data than can be fit into this buffer, then it will be expanded by according to the bufferSizeIncrement attribute, with an upper limit of maxInMemorySize. |  |
| Buffer Size Increment a| Number | This is by how much will be buffer size by expanded if it exceeds its initial size. Setting a value of zero or lower will mean that the buffer should not expand, meaning that a STREAM_MAXIMUM_SIZE_EXCEEDED error will be raised when the buffer gets full. |  |
| Max Buffer Size a| Number | This is the maximum amount of memory that will be used. If more than that is used then a STREAM_MAXIMUM_SIZE_EXCEEDED error will be raised. A value lower or equal to zero means no limit. |  |
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which all these attributes are expressed |  |
|===

[[repeatable-file-store-stream]]
=== Repeatable File Store Stream

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|===
| Field | Type | Description | Default Value | Required
| Max In Memory Size a| Number | Defines the maximum memory that the stream should use to keep data in memory. If more than that is consumed then it will start to buffer the content on disk. |  |
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which maxInMemorySize is expressed |  |
|===