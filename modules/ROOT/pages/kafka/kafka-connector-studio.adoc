= Kafka Studio Configuration - Mule 4
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

In Anypoint Studio, add Kafka Connector to a Mule project, configure the connection to the Kafka cluster, and configure an input source for the connector. 

To configure a connector in Anypoint Studio:

. Add the connector to a Mule project.
. Configure the connector.
. Configure an input source for the connector.

== Add the Connector in Studio

. In Studio, create a Mule Project.
. In the Mule Palette, click *(X) Search in Exchange*.
. In *Add Modules to Project*, type the name of the connector in the search field.
. Click the connector name in *Available modules*.
. Click *Add*.
. Click *Finish*.

== Add the Connector Using Exchange

. In Studio, create a Mule Project.
. Click the Exchange *(X)* icon in the upper-left of the Studio task bar.
. In Exchange, click *Login* and supply your Anypoint Platform username and password.
. In Exchange, select *All assets* and search for "Kafka".
. Select Kafka Connector and click *Add to project*.
. Follow the prompts to add the connector to the Mule project.

== Consumer Configuration

You can create a consumer configuration global element to reference from Kafka Connector. This enables you to apply configuration details to multiple local elements in the flow.

. In the Mule project canvas, click *Global Elements*.
. Click *Create* and expand *Connector Configuration*.
. Select *Apache Kafka Consumer configuration* and click *Ok*.
. For the connection, configure these fields:
+
* Bootstrap Server URLs +
List of host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the `bootstrap.servers` value you must provide to Kafka clients (producer or consumer).
* Bean Reference (Optional) +
The URLs that the consumer can use to connect to the Kafka cluster.
* Group ID +
Default group ID for all the Kafka consumers that use this configuration.
* Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to which to subscribe. Topics are automatically rebalanced according to the number of consumers of the topic.
* Assignments (Optional) +
The list of topic-partition pairs to assign. Consumers are not automatically rebalanced.
+
image::kafka/kafka-consumer-config.png[]

== Producer Configuration

Create a producer configuration global element:

. In the Mule project canvas, click *Global Elements*.
. Click *Create* and expand *Connector Configuration*.
. Select *Apache Kafka Producer configuration* and click *Ok*.
. For the producer connection, configure these fields:
+
* Bootstrap Server URLs +
List of host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the `bootstrap.servers` value you must provide to Kafka clients (producer or consumer).
* Bean Reference (Optional) +
The URLs that the producer can use to connect to the Kafka cluster.
+
image::kafka/kafka-producer-studio-config.png[

== Configure TLS

To enable TLS for your app:

. Click the *TLS* tab to configure the truststore and keystore:
* *Trust Store Configuration*
** Path +
The location of the truststore file.
** Password +
The password for the truststore file.
** Type +
The file format of the truststore file.
** Algorithm +
The algorithm the truststore uses. 
** Insecure +
Boolean that determines whether or not to validate the truststore. If set to true, no validation occurs. The default value is false.
* *Key Store Configuration*
** Type +
Optionally specify the file format of the keystore file. The default value is `JKS`.
** Path +
The location of the keystore file. This is optional and can be used for two-way authentication for the connector.
** Alias +
When the keystore contains many private keys, this attribute indicates the alias of the key to use. If not defined, the first key in the file is used by default.
** Key password +
The key manager password, which is the password for the private key inside the keystore.
** Password +
The store password for the keystore file. This is optional and needed only if the *Key Store Location* is configured.
** Algorithm +
The algorithm used in the keystore. 
+
image::kafka/kafka-tls-studio-config.png[]

== Configure the Commit Operation

. Drag the *Commit* operation to the Studio canvas.
. Configure the *Commit* operation in the *General* tab:
+
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Consumer commit key a| String |  The commitKey of the last poll. This operation is valid only when used inside a flow that is using one of the listener sources (*Batch message listener* or *Message listener*) which inserts this value as an attribute in the Mule event. |  | x
|===
+
image::kafka/kafka-commit-studio-config-general.png[]
. In the *Advanced* tab, configure the reconnection strategy. 

== Configure the Consume Operation

. Drag the *Consume* operation to the Studio canvas.
. Configure the *Consume* operation in the *General* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Consumption timeout a| Number |  The amount of time units that this operation will wait for receiving messages. |  | 
| Timeout time unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  The unit of time for the timeout property. |  |  
|===
+
image::kafka/kafka-consume-studio-config.png[]
+
. Configure the following settings in the *Advanced* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Operation Timeout a| Number |  |  | 
| Operation Timeout Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  |  | 
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* non-repeatable-stream |  Configure to use repeatable streams. |  | 
| Target Variable a| String |  The name of a variable that stores the operation's output. |  | 
| Target Value a| String |  An expression that evaluates the operation's output. The outcome of the evaluation is stored in the target variable. |  `#[payload]` | 
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  | 
|===

== Configure the Publish Operation

. Drag the *Publish* operation to the Studio canvas.
. Configure the *Publish* operation in the *General* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Topic a| String |  The topic to publish to. |  | 
| Partition a| Number |  (Optional) The topic partition.  |  | 
| Key a| Binary |  (Optional) Key for the published message. |  | 
| Message a| Binary |  (Optional) Message content of the message. |  `#[payload]` | 
| Headers a| Object |  (Optional) Headers for the message. |  |  
|===
+
image::kafka/kafka-publish-studio-config.png[]
+
. Configure the following settings in the *Advanced* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can take regarding transactions. |  `JOIN_IF_POSSIBLE` | 
| Target Variable a| String |  The name of a variable to store the operation's output. |  | 
| Target Value a| String |  An expression to evaluate against the operation's output and store the expression outcome in the target variable. |  `#[payload]` | 
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  | 
|===

== Configure the Seek Operation

. Drag the *Seek* operation to the Studio canvas.
. Configure the *Seek* operation in the *General* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Topic a| String |  The name of the topic on which to perform the seek operation. |  | x
| Partition a| Number |  The partition number that will have its offset modified. |  | x 
|===
+
. Configure the following settings in the *Advanced* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Operation Timeout a| Number |  |  | 
| Operation Timeout Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  |  | 
| Reconnection Strategy a| * <<reconnect>>
* <<reconnect-forever>> |  A retry strategy in case of connectivity errors. |  | 
|===

== Configure an Input Source

Configure an input source for the connector, such as the *Message Consumer* operation:

[%header,cols="30s,70a"]
|===
| Name | Description
| Configuration |The name of the configuration to use.
| Topic |Name of the topic from which to consume messages.
| Primary Node Only |Whether to execute this source on only the primary node when running in a cluster.
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

Configure to use repeatable streams.
| Redelivery Policy a| Defines a policy for processing the redelivery of the same message.
| Reconnection Strategy a| A retry strategy in case of connectivity errors.

* reconnect
* reconnect-forever 
|===


The *Batch Message Listener* operation can also be used as an input source in Kafka Connector:

[%header,cols="30s,70a"]
|===
| Name | Description
| Connector Configuration |The name of the configuration to use.
| Poll timeout |The amount of time to block. 
| Poll timeout time unit |  The time unit for the polling timeout. This combines with poll timeout to define the total timeout for the polling.
| Acknowledgment mode | Declares the supported acknowledgment mode type.
| Amount of parallel consumers | Declares how many consumers to use in parallel.
| Primary Node Only |Whether this source should be executed only on the primary node when running in a cluster.
| Streaming Strategy a| Define the streaming strategy. 

* repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

| Redelivery Policy a| Defines a policy for processing the redelivery of the same message.
| Reconnection Strategy a| A retry strategy in case of connectivity errors.

* reconnect
* reconnect-forever 
|===

== See Also

https://help.mulesoft.com[MuleSoft Help Center]
