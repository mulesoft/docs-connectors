= Kafka Studio Configuration - Mule 4
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

In Anypoint Studio, add Kafka Connector to a Mule project, configure the connection to the Kafka cluster, and configure an input source for the connector. 

To configure a connector in Anypoint Studio:

. Add the connector to a Mule project.
. Configure the connector.
. Configure an input source for the connector.

== Add the Connector in Studio

. In Studio, create a Mule Project.
. In the Mule Palette, click *(X) Search in Exchange*.
. In *Add Modules to Project*, type the name of the connector in the search field.
. Click the connector name in *Available modules*.
. Click *Add*.
. Click *Finish*.

== Add the Connector Using Exchange

. In Studio, create a Mule Project.
. Click the Exchange *(X)* icon in the upper-left of the Studio task bar.
. In Exchange, click *Login* and supply your Anypoint Platform username and password.
. In Exchange, select *All assets* and search for "Kafka".
. Select Kafka Connector and click *Add to project*.
. Follow the prompts to install the connector.

== Configure the Connector

. Drag the connector operation to the Studio Canvas.
. To create a global element for the connector, set these fields:
+
.. Basic:
** Bootstrap Servers +
Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the `bootstrap.servers` value you must provide to Kafka clients (producer or consumer).
** Additional properties +
Add any additional properties that you need for your connection, and that Kafka supports, as key-value pairs.
+
image::kafka/kafka-basic-studio-config.png[]
+
.. SSL:
** All the parameters from Basic configuration.
** Key Store Type +
Optionally specify the file format of the key store file. The default value is `JKS`.
** Key Store Password +
The store password for the key store file. This is optional and needed only if the *Key Store Location* is configured.
** Key Store Location +
The location of the key store file. This is optional and can be used for two-way authentication for the connector.
** Trust Store Type +
The file format of the truststore file.
** Trust Store Password +
The password for the truststore file.
** Trust Store Location +
The location of the truststore file.
+
image::kafka/kafka-ssl-studio-config.png[]
+
.. Kerberos:
** All the parameters from the Basic configuration.
** Principal +
The Kerberos principal to which Kerberos can assign tickets.
** Keytab +
Path to keytab file associated with the `principal`.
** Service Name +
The Kerberos principal name that the Kafka broker runs as.
** Additional JAAS Properties +
Additional properties as key-value pairs that you set in `sasl.jaas.config` and that you usually include in JAAS configuration file.
+
image::kafka/kafka-kerberos-studio-config.png[]
+
.. Kerberos SSL:
** All the parameters from the Basic configuration.
** All the parameters from the SSL configuration.
** All the parameters from the Kerberos configuration.
+
image::kafka/kafka-kerberos-ssl-studio-config.png[]
+
. Based on the operation that you dragged to the canvas, configure the following fields:
.. Commit operation:
** Bean Reference (Optional) +
The URLs that the consumer can use to try to connect to the Kafka cluster.
** Group ID +
Default group ID for all the Kafka consumers that use this configuration.
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) +
The list of topic-partition pairs to assign. Note that there will be no automatic rebalance of the consumers.
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgement mode +
Declares the type of supported Acknowledgement mode
** Default poll timeout +
The amount of time unit to block
** Default poll timeout time unit +
The time unit for the polling timeout. This combines with pollTimeout to define to total timeout for the polling.
** Zone ID (Optional) +
Zone ID is used to convert the provided time stamps into ZonedLocalDateTimes in the results. Default value is the system one.
+
image::kafka/kafka-consumer-studio-config-general.png[]
+
.. Consume operation:
** Bean Reference (Optional) +
The URLs that the consumer can use to try to connect to the Kafka cluster
** Group ID +
Default group ID for all the Kafka consumers that use this configuration
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) + 
The list of topic-partition pairs to assign. Note that there will be no automatic rebalance of the consumers
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgement mode +
Declares the kind of Acknowledgement mode supported
** Default poll timeout + 
The amount of time to block
** Default poll timeout time unit +
The time unit for the polling timeout. This combines with pollTimeout to define to total timeout for the polling.
** Zone ID (Optional) +
Zone ID is used to convert the provided time stamps into ZonedLocalDateTimes in the results. Default value is the system one.
+
image::kafka/kafka-producer-studio-config-general.png[]
+
.. Describe operation:
** Bean Reference (Optional) +
The URLs that the consumer can use to try to connect to the Kafka cluster
** Group ID +
Default group ID for all the Kafka consumers that use this configuration
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) +
The list of topic-partition pairs to assign. Note that there will be no automatic rebalance of the consumers
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgement mode +
Declares the type of Acknowledgement mode supported
** Default poll timeout +
The amount of time unit to block
** Default poll timeout time unit +
The time unit for the polling timeout. This combines with pollTimeout to define to total timeout for the polling.
** Zone ID (Optional) +
Zone ID is used to convert the provided time stamps into ZonedLocalDateTimes in the results. Default value is the system one.
+
image::kafka/kafka-consumer-studio-config-general.png[]
+
.. Publish operation:
** Bean Reference (Optional) +
The URLs that the consumer can use to try to connect to the Kafka cluster
+
image::kafka/kafka-consumer-studio-config-publish.png[]
+
** Default topic +
A default topic name
+
image::kafka/kafka-consumer-studio-config-publish-general.png[]
+
.. Seek operation:
** Bean Reference (Optional) +
The URLs that the consumer can use to try to connect to the Kafka cluster
** Group ID +
Default group ID for all the Kafka consumers that use this configuration
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) +
The list of topic-partition pairs to assign. Note that there will be no automatic rebalance of the consumers
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgement mode +
Declares the kind of Acknowledgement mode supported
** Default poll timeout +
The amount of time unit to block
** Default poll timeout time unit +
The time unit for the polling timeout. This combines with pollTimeout to define the total timeout for the polling.
** Zone ID (Optional) +
Zone ID is used to convert the provided time stamps into ZonedLocalDateTimes in the results. Default value is the system one.
+
image::kafka/kafka-consumer-studio-config-general.png[]


== Configure an Input Source

Configure an input source for the connector such as a connector operation, using an *HTTP Listener*, or *Scheduler*.

The *Message Consumer* operation can be used as an input source in Kafka Connector.

*Message Consumer* fields:

[%header,cols="30s,70a"]
|===
| Name | Description
| Configuration |The name of the configuration to use.
| Topic |Name of the topic to consume messages from.
| Partition Offsets a| Array of Offset - List of Offset representing partitions offsets configuration. For each element in the list you must specify partition index and offset.
| Primary Node Only |Whether to execute this source on only the primary node when running in a cluster.
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

Configure to use repeatable streams.
| Redelivery Policy a| RedeliveryPolicy -  Defines a policy for processing the redelivery of the same message.
| Reconnection Strategy a| * reconnect
* reconnect-forever -  A retry strategy in case of connectivity errors.
|===


The *Batch Message Consumer* operation can also be used as an input source in Kafka Connector.

*Message Consumer* fields:

[%header,cols="30s,70a"]
|===
| Name | Description
| Configuration |The name of the configuration to use.
| Poll timeout |The amount of time units to block
| Poll timeout time unit |  The time unit for the polling timeout. This combines with pollTimeout to define to total timeout for the polling.
| Acknowledgement mode | Declares the kind of supported Acknowledgement mode
| Amount of parallel consumers | Declares how many consumers will be used in parallel
| Primary Node Only |Whether this source should only be executed on the primary node when running in Cluster.
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

Configure to use repeatable streams.
| Redelivery Policy a| RedeliveryPolicy -  Defines a policy for processing the redelivery of the same message.
| Reconnection Strategy a| * reconnect
* reconnect-forever -  A retry strategy in case of connectivity errors.

|===

== See Also

https://help.mulesoft.com[MuleSoft Help Center]

