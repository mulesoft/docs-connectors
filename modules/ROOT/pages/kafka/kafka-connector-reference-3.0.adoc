= Apache Kafka Connector Reference - Mule 4
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

Support Category: https://www.mulesoft.com/legal/versioning-back-support-policy#anypoint-connectors[Select]

Kafka Connector v3.0

Anypoint Connector for Apache Kafka (Kafka Connector) allows you to interact with the Apache Kafka messaging system, and enable seamless integration between your Mule app and an Apache Kafka cluster, using Mule runtime.

Release Notes: xref:release-notes::connector/kafka-connector-release-notes-mule-4.adoc[Kafka Connector Release Notes]

== Configurations
---
[[KafkaConsumerConfig]]
=== Consumer configuration


==== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
|Name | String | The name for this configuration. Connectors reference the configuration with this name. | | *x*{nbsp}
| Connection a| * <<KafkaConsumerConfig_BasicKafkaConsumerConnection, Kafka Basic Consumer Connection>> {nbsp}
* <<KafkaConsumerConfig_KerberosKafkaConsumerConnection, Kafka Kerberos Consumer Connection>> {nbsp}
* <<KafkaConsumerConfig_KerberosSslKafkaConsumerConnection, Kafka Kerbero SSL Consumer Connection>> {nbsp}
* <<KafkaConsumerConfig_SslKafkaConsumerConnection, Kafka SSL Consumer Connection>> {nbsp}
 | The connection types that can be provided to this configuration. | | *x*{nbsp}
| Name a| String |  The identifier of this element used to reference it in other components |  | *x*{nbsp}
| Expiration Policy a| <<ExpirationPolicy>> |  Configures the minimum amount of time that a dynamic configuration instance can remain idle before the runtime considers it eligible for expiration. This does not mean that the platform will expire the instance at the exact moment that it becomes eligible. The runtime will actually purge the instances when it sees it fit. |  | {nbsp}
|===

==== Connection Types
[[KafkaConsumerConfig_BasicKafkaConsumerConnection]]
===== Kafka Basic Consumer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 | {nbsp}
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | *x*{nbsp}
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
|===
[[KafkaConsumerConfig_KerberosKafkaConsumerConnection]]
===== Kafka Kerberos Consumer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 | {nbsp}
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | *x*{nbsp}
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
| Kerberos Config File a| String |  Kerberos configuration file krb5.conf. The essential Kerberos configuration information is the default realm and the default KDC. Optional if the path was provided as "java.security.krb5.conf" VM parameter or if the config file is already placed in one of the locations where the java distribution looks for the config for example oracle distribution searches as follows: - \conf\security (Windows) - /conf/security (Solaris, Linux, and macOS) - /etc/krb5/krb5.conf (Solaris) - C:\Windows\krb5.ini (Windows) - /etc/krb5.conf (Linux) - ~/Library/Preferences/edu.mit.Kerberos, /Library/Preferences/edu.mit.Kerberos, or /etc/krb5.conf (macOS) |  | {nbsp}
| Principal a| String |  Kerberos principal |  | *x*{nbsp}
| Keytab a| String |  Path to keytab file associated with "principal". |  | *x*{nbsp}
| Service Name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | *x*{nbsp}
| Additional JAAS Properties a| Object |  Additional properties as key-&gt;value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  | {nbsp}
|===
[[KafkaConsumerConfig_KerberosSslKafkaConsumerConnection]]
===== Kafka Kerbero SSL Consumer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 | {nbsp}
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | *x*{nbsp}
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
| Key Store Type a| String |  The file format of the key store file. This is optional and default value is "JKS". |  JKS | {nbsp}
| Key Store Password a| String |  The store password for the key store file. This is optional and only needed if "keyStoreLocation" is configured. |  | {nbsp}
| Key Store Location a| String |  The location of the key store file. This is optional and can be used for two-way authentication for connector. |  | {nbsp}
| Trust Store Type a| String |  The file format of the trust store file. |  JKS | {nbsp}
| Trust Store Password a| String |  The password for the trust store file. |  | *x*{nbsp}
| Trust Store Location a| String |  The location of the trust store file. |  | *x*{nbsp}
| Kerberos Config File a| String |  Kerberos configuration file krb5.conf. The essential Kerberos configuration information is the default realm and the default KDC. Optional if the path was provided as "java.security.krb5.conf" VM parameter or if the config file is already placed in one of the locations where the java distribution looks for the config for example oracle distribution searches as follows: - \conf\security (Windows) - /conf/security (Solaris, Linux, and macOS) - /etc/krb5/krb5.conf (Solaris) - C:\Windows\krb5.ini (Windows) - /etc/krb5.conf (Linux) - ~/Library/Preferences/edu.mit.Kerberos, /Library/Preferences/edu.mit.Kerberos, or /etc/krb5.conf (macOS) |  | {nbsp}
| Principal a| String |  Kerberos principal |  | *x*{nbsp}
| Keytab a| String |  Path to keytab file associated with "principal". |  | *x*{nbsp}
| Service Name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | *x*{nbsp}
| Additional JAAS Properties a| Object |  Additional properties as key-&gt;value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  | {nbsp}
|===
[[KafkaConsumerConfig_SslKafkaConsumerConnection]]
===== Kafka SSL Consumer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Consumer Partitions a| Number |  The number of partitions to be used for the consumer |  1 | {nbsp}
| Group Id a| String |  A unique string that identifies the consumer group this consumer belongs to. |  | *x*{nbsp}
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
| Key Store Type a| String |  The file format of the key store file. This is optional and default value is "JKS". |  JKS | {nbsp}
| Key Store Password a| String |  The store password for the key store file. This is optional and only needed if "keyStoreLocation" is configured. |  | {nbsp}
| Key Store Location a| String |  The location of the key store file. This is optional and can be used for two-way authentication for connector. |  | {nbsp}
| Trust Store Type a| String |  The file format of the trust store file. |  JKS | {nbsp}
| Trust Store Password a| String |  The password for the trust store file. |  | *x*{nbsp}
| Trust Store Location a| String |  The location of the trust store file. |  | *x*{nbsp}
|===


==== Associated Sources
* <<Consumer>> {nbsp}

---
[[KafkaProducerConfig]]
=== Producer configuration


==== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
|Name | String | The name for this configuration. Connectors reference the configuration with this name. | | *x*{nbsp}
| Connection a| * <<KafkaProducerConfig_BasicKafkaProducerConnection, Kafka Basic Producer Connection>> {nbsp}
* <<KafkaProducerConfig_KerberosKafkaProducerConnection, Kafka Kerberos Producer Connection>> {nbsp}
* <<KafkaProducerConfig_KerberosSslKafkaProducerConnection, Kafka Kerberos SSL Producer Connection>> {nbsp}
* <<KafkaProducerConfig_SslKafkaProducerConnection, Kafka SSL Producer Connection>> {nbsp}
 | The connection types that can be provided to this configuration. | | *x*{nbsp}
| Name a| String |  The identifier of this element used to reference it in other components |  | *x*{nbsp}
| Expiration Policy a| <<ExpirationPolicy>> |  Configures the minimum amount of time that a dynamic configuration instance can remain idle before the runtime considers it eligible for expiration. This does not mean that the platform will expire the instance at the exact moment that it becomes eligible. The runtime will actually purge the instances when it sees it fit. |  | {nbsp}
|===

==== Connection Types
[[KafkaProducerConfig_BasicKafkaProducerConnection]]
===== Kafka Basic Producer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
|===
[[KafkaProducerConfig_KerberosKafkaProducerConnection]]
===== Kafka Kerberos Producer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
| Kerberos Config File a| String |  Kerberos configuration file krb5.conf. The essential Kerberos configuration information is the default realm and the default KDC. Optional if the path was provided as "java.security.krb5.conf" VM parameter or if the config file is already placed in one of the locations where the java distribution looks for the config for example oracle distribution searches as follows: - \conf\security (Windows) - /conf/security (Solaris, Linux, and macOS) - /etc/krb5/krb5.conf (Solaris) - C:\Windows\krb5.ini (Windows) - /etc/krb5.conf (Linux) - ~/Library/Preferences/edu.mit.Kerberos, /Library/Preferences/edu.mit.Kerberos, or /etc/krb5.conf (macOS) |  | {nbsp}
| Principal a| String |  Kerberos principal |  | *x*{nbsp}
| Keytab a| String |  Path to keytab file associated with "principal". |  | *x*{nbsp}
| Service Name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | *x*{nbsp}
| Additional JAAS Properties a| Object |  Additional properties as key-&gt;value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  | {nbsp}
|===
[[KafkaProducerConfig_KerberosSslKafkaProducerConnection]]
===== Kafka Kerberos SSL Producer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
| Key Store Type a| String |  The file format of the key store file. This is optional and default value is "JKS". |  JKS | {nbsp}
| Key Store Password a| String |  The store password for the key store file. This is optional and only needed if "keyStoreLocation" is configured. |  | {nbsp}
| Key Store Location a| String |  The location of the key store file. This is optional and can be used for two-way authentication for connector. |  | {nbsp}
| Trust Store Type a| String |  The file format of the trust store file. |  JKS | {nbsp}
| Trust Store Password a| String |  The password for the trust store file. |  | *x*{nbsp}
| Trust Store Location a| String |  The location of the trust store file. |  | *x*{nbsp}
| Kerberos Config File a| String |  Kerberos configuration file krb5.conf. The essential Kerberos configuration information is the default realm and the default KDC. Optional if the path was provided as "java.security.krb5.conf" VM parameter or if the config file is already placed in one of the locations where the java distribution looks for the config for example oracle distribution searches as follows: - \conf\security (Windows) - /conf/security (Solaris, Linux, and macOS) - /etc/krb5/krb5.conf (Solaris) - C:\Windows\krb5.ini (Windows) - /etc/krb5.conf (Linux) - ~/Library/Preferences/edu.mit.Kerberos, /Library/Preferences/edu.mit.Kerberos, or /etc/krb5.conf (macOS) |  | {nbsp}
| Principal a| String |  Kerberos principal |  | *x*{nbsp}
| Keytab a| String |  Path to keytab file associated with "principal". |  | *x*{nbsp}
| Service Name a| String |  The Kerberos principal name that Kafka Broker runs as. |  | *x*{nbsp}
| Additional JAAS Properties a| Object |  Additional properties as key-&gt;value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file. |  | {nbsp}
|===
[[KafkaProducerConfig_SslKafkaProducerConnection]]
===== Kafka SSL Producer Connection


====== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Bootstrap Servers a| String |  Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the "bootstrap.servers" value you must provide to Kafka clients (producer/consumer). |  | *x*{nbsp}
| Additional Properties a| Object |  Additional properties as key-&gt;value that you need for your connection. |  | {nbsp}
| Reconnection a| <<Reconnection>> |  When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | {nbsp}
| Key Store Type a| String |  The file format of the key store file. This is optional and default value is "JKS". |  JKS | {nbsp}
| Key Store Password a| String |  The store password for the key store file. This is optional and only needed if "keyStoreLocation" is configured. |  | {nbsp}
| Key Store Location a| String |  The location of the key store file. This is optional and can be used for two-way authentication for connector. |  | {nbsp}
| Trust Store Type a| String |  The file format of the trust store file. |  JKS | {nbsp}
| Trust Store Password a| String |  The password for the trust store file. |  | *x*{nbsp}
| Trust Store Location a| String |  The location of the trust store file. |  | *x*{nbsp}
|===

==== Associated Operations
* <<Producer>> {nbsp}



== Operations

[[Producer]]
== Publish Message
`<kafka:producer>`


Sends messages to a Kafka topic.


=== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | *x*{nbsp}
| Topic a| String |  Topic to send the message to |  | *x*{nbsp}
| Key a| String |  Key belonging to the message that is going to be sent |  | {nbsp}
| Message a| Any |  Message to be sent |  #[payload] | {nbsp}
| Config Ref a| ConfigurationProvider |  The name of the configuration to be used to execute this component |  | *x*{nbsp}
| Reconnection Strategy a| * <<Reconnect>>
* <<ReconnectForever>> |  A retry strategy in case of connectivity errors |  | {nbsp}
|===


=== For Configurations

* <<KafkaProducerConfig>> {nbsp}

=== Throws

* KAFKA:CONNECTIVITY {nbsp}
* KAFKA:RETRY_EXHAUSTED {nbsp}
* KAFKA:UNABLE_TO_SEND_MESSAGE {nbsp}
* KAFKA:VALIDATION {nbsp}


== Sources

[[Consumer]]
== Message Consumer
`<kafka:consumer>`


Source that consumes messages from a given topic.


=== Parameters

[%header%autowidth.spread]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | *x*{nbsp}
| Topic a| String |  Name of the topic to consume messages from. |  | *x*{nbsp}
| Partition Offsets a| Array of <<Offset>> |  List of objects that contain the index of the partition and the offset. |  | {nbsp}
| Config Ref a| ConfigurationProvider |  The name of the configuration to be used to execute this component |  | *x*{nbsp}
| Primary Node Only a| Boolean |  Whether this source should only be executed on the primary node when runnning in Cluster |  | {nbsp}
| Streaming Strategy a| * <<RepeatableInMemoryStream>>
* <<RepeatableFileStoreStream>>
* non-repeatable-stream |  Configure if repeatable streams should be used and their behaviour |  | {nbsp}
| Redelivery Policy a| <<RedeliveryPolicy>> |  Defines a policy for processing the redelivery of the same message |  | {nbsp}
| Reconnection Strategy a| * <<Reconnect>>
* <<ReconnectForever>> |  A retry strategy in case of connectivity errors |  | {nbsp}
|===

=== Output

[%autowidth.spread]
|===
| *Type* a| Any
| *Attributes Type* a| <<KafkaMessageAttributes>>
|===

=== For Configurations

* <<KafkaConsumerConfig>> {nbsp}



== Types
[[Reconnection]]
=== Reconnection

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Fails Deployment a| Boolean | When the application is deployed, a connectivity test is performed on all connectors. If set to true, deployment will fail if the test doesn't pass after exhausting the associated reconnection strategy |  | 
| Reconnection Strategy a| * <<Reconnect>>
* <<ReconnectForever>> | The reconnection strategy to use |  | 
|======================

[[Reconnect]]
=== Reconnect

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often (in ms) to reconnect |  | 
| Blocking a| Boolean | If false, the reconnection strategy will run in a separate, non-blocking thread |  | 
| Count a| Number | How many reconnection attempts to make |  | 
|======================

[[ReconnectForever]]
=== Reconnect Forever

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Frequency a| Number | How often (in ms) to reconnect |  | 
| Blocking a| Boolean | If false, the reconnection strategy will run in a separate, non-blocking thread |  | 
|======================

[[ExpirationPolicy]]
=== Expiration Policy

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Max Idle Time a| Number | A scalar time value for the maximum amount of time a dynamic configuration instance should be allowed to be idle before it's considered eligible for expiration |  | 
| Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS | A time unit that qualifies the maxIdleTime attribute |  | 
|======================

[[KafkaMessageAttributes]]
=== Kafka Message Attributes

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Topic a| String |  |  | x
| Key a| String |  |  | x
| Partition a| Number |  |  | x
| Offset a| Number |  |  | x
|======================

[[Offset]]
=== Offset

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Partition Number a| String |  |  | x
| Partition Offset a| String |  |  | x
|======================

[[RepeatableInMemoryStream]]
=== Repeatable In Memory Stream

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Initial Buffer Size a| Number | This is the amount of memory that will be allocated in order to consume the stream and provide random access to it. If the stream contains more data than can be fit into this buffer, then it will be expanded by according to the bufferSizeIncrement attribute, with an upper limit of maxInMemorySize. |  | 
| Buffer Size Increment a| Number | This is by how much will be buffer size by expanded if it exceeds its initial size. Setting a value of zero or lower will mean that the buffer should not expand, meaning that a STREAM_MAXIMUM_SIZE_EXCEEDED error will be raised when the buffer gets full. |  | 
| Max Buffer Size a| Number | This is the maximum amount of memory that will be used. If more than that is used then a STREAM_MAXIMUM_SIZE_EXCEEDED error will be raised. A value lower or equal to zero means no limit. |  | 
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which all these attributes are expressed |  | 
|======================

[[RepeatableFileStoreStream]]
=== Repeatable File Store Stream

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| In Memory Size a| Number | Defines the maximum memory that the stream should use to keep data in memory. If more than that is consumed then it will start to buffer the content on disk. |  | 
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which maxInMemorySize is expressed |  | 
|======================

[[RedeliveryPolicy]]
=== Redelivery Policy

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Max Redelivery Count a| Number | The maximum number of times a message can be redelivered and processed unsuccessfully before triggering process-failed-message |  | 
| Message Digest Algorithm a| String | The secure hashing algorithm to use. If not set, the default is SHA-256. |  | 
| Message Identifier a| <<RedeliveryPolicyMessageIdentifier>> | Defines which strategy is used to identify the messages. |  | 
| Object Store a| ObjectStore | The object store where the redelivery counter for each message is going to be stored. |  | 
|======================

[[RedeliveryPolicyMessageIdentifier]]
=== Redelivery Policy Message Identifier

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Use Secure Hash a| Boolean | Whether to use a secure hash algorithm to identify a redelivered message |  | 
| Id Expression a| String | Defines one or more expressions to use to determine when a message has been redelivered. This property may only be set if useSecureHash is false. |  | 
|======================

== See Also

https://help.mulesoft.com[MuleSoft Help Center]
