= Using Anypoint Studio to Configure Apache Kafka - Mule 4

In Anypoint Studio, add Anypoint Connector for Apache Kafka (Apache Kafka Connector) to a Mule project, configure the connection to the Kafka cluster, and configure an input source for the connector.

To configure a connector in Anypoint Studio:

. Add the connector to a Mule project.
. Configure the connector.
. Configure an input source for the connector.

== Add the Connector in Studio

. In Studio, create a Mule Project.
. In the Mule Palette, click *(X) Search in Exchange*.
. In *Add Modules to Project*, type the name of the connector in the search field.
. Click the connector name in *Available modules*.
. Click *Add*.
. Click *Finish*.

== Add the Connector Using Exchange

. In Studio, create a Mule Project.
. Click the Exchange *(X)* icon in the upper-left of the Studio task bar.
. In Exchange, click *Login* and supply your Anypoint Platform username and password.
. In Exchange, select *All assets* and search for `Apache Kafka`.
. Select the connector and click *Add to project*.
. Follow the prompts to add the connector to the Mule project.

== Consumer Configuration

You can create a consumer configuration global element to reference from Apache Kafka Connector. This enables you to apply configuration details to multiple local elements in the flow.

. In the Mule project canvas, click *Global Elements*.
. Click *Create* and expand *Connector Configuration*.
. Select *Kafka Consumer configuration* and click *Ok*.
. For the connection, configure these fields:
+
* Bootstrap Server URLs +
List of host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the `bootstrap.servers` value you must provide to Kafka clients (producer or consumer).
* Bean Reference (Optional) +
URLs that the consumer can use to connect to the Kafka cluster.
* Group ID +
Default group ID for all the Kafka consumers that use this configuration.
* Topic Subscription Patterns (Optional) +
List of subscription regular expressions to which to subscribe. Topics are automatically rebalanced according to the number of consumers of the topic.
* Assignments (Optional) +
List of topic-partition pairs to assign. Consumers are not automatically rebalanced.
+
image::kafka-consumer-config.png[]

== Producer Configuration

Create a producer configuration global element:

. In the Mule project canvas, click *Global Elements*.
. Click *Create* and expand *Connector Configuration*.
. Select *Kafka Producer configuration* and click *Ok*.
. For the producer connection, configure these fields:
+
* Bootstrap Server URLs +
List of host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the `bootstrap.servers` value you must provide to Kafka clients (producer or consumer).
* Bean Reference (Optional) +
The URLs that the producer can use to connect to the Kafka cluster.
+
image::kafka-producer-studio-config.png[]

== Configure TLS

To enable TLS for your app:

. Click the *TLS* tab to configure the truststore and keystore:
* *Trust Store Configuration*
** Path +
Location of the truststore file.
** Password +
Password for the truststore file.
** Type +
File format of the truststore file.
** Algorithm +
Algorithm the truststore uses.
** Insecure +
Boolean that determines whether or not to validate the truststore. If set to `true`, no validation occurs. The default value is `false`.
* *Key Store Configuration*
** Type +
Optionally specify the file format of the keystore file. The default value is `JKS`.
** Path +
Location of the keystore file. This is optional and can be used for two-way authentication for the connector.
** Alias +
Attribute that indicates the alias of the key to use when the keystore contains many private keys. If not defined, the first key in the file is used by default.
** Key password +
Key manager password, which is the password for the private key inside the keystore.
** Password +
Store password for the keystore file. This is optional and needed only if the *Key Store Location* is configured.
** Algorithm +
Algorithm used in the keystore.
+
image::kafka-tls-studio-config.png[]

== Configure the Commit Operation

. Drag the *Commit* operation to the Studio canvas.
. Configure the *Commit* operation in the *General* tab:
+
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Consumer commit key a| String |  The commitKey of the last poll. This operation is valid only when used inside a flow that is using one of the listener sources (*Batch message listener* or *Message listener*) which inserts this value as an attribute in the Mule event. |  | x
|===
+
image::kafka-commit-studio-config-general.png[]
. In the *Advanced* tab, configure the reconnection strategy.

== Configure the Consume Operation

. Drag the *Consume* operation to the Studio canvas.
. Configure the *Consume* operation in the *General* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Consumption timeout a| Number | The number of time units that this operation waits for receiving messages. |  |
| Timeout time unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS | The unit of time for the timeout property. |  |
|===
+
image::kafka-consume-studio-config.png[]
+
. Configure the following settings in the *Advanced* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Operation Timeout a| Number |  |  |
| Operation Timeout Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  |  |
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream |  Configure to use repeatable streams. |  |
| Target Variable a| String |  The name of a variable that stores the operation's output. |  |
| Target Value a| String |  An expression that evaluates the operation's output. The outcome of the evaluation is stored in the target variable. |  `#[payload]` |
| Reconnection Strategy a| * reconnect
* reconnect-forever |  A retry strategy in case of connectivity errors. |  |
|===

== Configure the Publish Operation

. Drag the *Publish* operation to the Studio canvas.
. Configure the *Publish* operation in the *General* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Topic a| String |  The topic to publish to. |  |
| Partition a| Number |  (Optional) The topic partition.  |  |
| Key a| Binary |  (Optional) Key for the published message. |  |
| Message a| Binary |  (Optional) Message content of the message. |  `#[payload]` |
| Headers a| Object |  (Optional) Headers for the message. |  |
|===
+
image::kafka-publish-studio-config.png[]
+
. Configure the following settings in the *Advanced* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Transactional Action a| Enumeration, one of:

** ALWAYS_JOIN
** JOIN_IF_POSSIBLE
** NOT_SUPPORTED |  The type of joining action that operations can take regarding transactions. |  `JOIN_IF_POSSIBLE` |
| Target Variable a| String |  The name of a variable to store the operation's output. |  |
| Target Value a| String |  An expression to evaluate against the operation's output and store the expression outcome in the target variable. |  `#[payload]` |
| Reconnection Strategy a| * reconnect
* reconnect-forever |  A retry strategy in case of connectivity errors. |  |
|===

== Configure the Seek Operation

. Drag the *Seek* operation to the Studio canvas.
. Configure the *Seek* operation in the *General* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | x
| Topic a| String |  The name of the topic on which to perform the seek operation. |  | x
| Partition a| Number |  The partition number that will have its offset modified. |  | x
|===
+
. Configure the following settings in the *Advanced* tab:
+
[%header,cols="20s,20a,35a,20a,5a"]
|===
| Name | Type | Description | Default Value | Required
| Operation Timeout a| Number |  |  |
| Operation Timeout Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS |  |  |
| Reconnection Strategy a| * reconnect
* reconnect-forever |  A retry strategy in case of connectivity errors. |  |
|===

== Configure an Input Source

Configure an input source for the connector, such as the *Message Consumer* operation:

[%header,cols="30s,70a"]
|===
| Name | Description
| Configuration |The name of the configuration to use.
| Topic |Name of the topic from which to consume messages.
| Primary Node Only |Whether to execute this source on only the primary node when running in a cluster.
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

Configure to use repeatable streams.
| Redelivery Policy a| Defines a policy for processing the redelivery of the same message.
| Reconnection Strategy a| A retry strategy in case of connectivity errors.

* reconnect
* reconnect-forever
|===


You can also use the *Batch Message Listener* operation as an input source in Apache Kafka Connector:

[%header,cols="30s,70a"]
|===
| Name | Description
| Connector Configuration |The name of the configuration to use.
| Poll timeout |The amount of time to block.
| Poll timeout time unit |  The time unit for the polling timeout. This combines with poll timeout to define the total timeout for the polling.
| Acknowledgment mode | Declares the supported acknowledgment mode type.
| Amount of parallel consumers | Declares how many consumers to use in parallel.
| Primary Node Only |Whether this source should be executed only on the primary node when running in a cluster.
| Streaming Strategy a| Define the streaming strategy.

* repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

| Redelivery Policy a| Defines a policy for processing the redelivery of the same message.
| Reconnection Strategy a| A retry strategy in case of connectivity errors.

* reconnect
* reconnect-forever
|===

== See Also

* xref:connectors::introduction/introduction-to-anypoint-connectors.adoc[Introduction to Anypoint Connectors]
* https://help.mulesoft.com[MuleSoft Help Center]
